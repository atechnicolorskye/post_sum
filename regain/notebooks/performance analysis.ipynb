{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance analysis\n",
    "This notebook is create to compare the performance of different algorithms for graphical inference, namely graphical lasso (GL or GLASSO), latent graph lasso (LVGLASSO), time-varying graphical lasso (TVGL) with our method, latent variable time-varying graphical lasso (LVGL).\n",
    "\n",
    "## Before proceeding\n",
    "Other methods are not necessarily implemented in Python. Therefore, this is a list of required steps in order to successfully install the code.\n",
    "\n",
    "### Install instructions for\n",
    "* GL (scikit-learn implementation)\n",
    "For this, it is not required to do anything, as `sklearn` should be already installed in your system as it is a dependency of `regain`. Otherwise, install it as first thing with \n",
    "```\n",
    "conda install scikit-learn\n",
    "```\n",
    "or \n",
    "```\n",
    "pip install scikit-learn\n",
    "```\n",
    "\n",
    "* GLASSO (R implementation)\n",
    "This is the R implementation for graphical lasso, called GLASSO. It is available as an R package, thus requiring R installed in your system. Then, in R console (simply call `R` from a command line):\n",
    "```R\n",
    "install.packages(\"glasso\")\n",
    "```\n",
    "Refer to [GLASSO documentation](https://cran.r-project.org/web/packages/glasso/glasso.pdf) for further information.\n",
    "\n",
    "* LVGLASSO (Matlab implementation)\n",
    "This requires to have either `oct2py` or [Matlab installed](https://it.mathworks.com/help/install/ug/install-mathworks-software.html) (version2016b or higher) and [Matlab engine for Python](https://it.mathworks.com/help/matlab/matlab_external/install-the-matlab-engine-for-python.html).\n",
    "Then, [download the code](https://www.math.ucdavis.edu/~sqma/ADMM-LVGLasso) and unpack the folder.\n",
    "Ensure to have a file called `ADMM_B.m`. Save the location of the code, as it will be needed to call the `ADMM_B.m` script.\n",
    "\n",
    "**NOTE 1:** There is a so-called [LVGLASSO in the R packages](https://www.rdocumentation.org/packages/lvnet/versions/0.3.2/topics/lvglasso). Note that THIS IS NOT RIGHT, as it is implemented in a different way and it requires to specify a priori the number of latent variables. See the link above for further details.\n",
    "\n",
    "**NOTE 2:** Our `regain` package has a Python wrapper that ease the calling of such Matlab functions. Therefore, conversions of numpy arrays to Matlab matrices are done under the hood from the script `regain/wrappers/lvglasso/LVGLASSO.m`.\n",
    "\n",
    "* TVGL (Python implementation)\n",
    "Since it is a Python implementation, this does not require additional software (beside having `git` installed). However, there is a little modification in the source code to do in order to obtain additional results, such as the number of iterations and the estimated covariance matrices.\n",
    "\n",
    "1. Clone the repo (https://github.com/davidhallac/TVGL) in a folder, with\n",
    "```bash\n",
    "git clone https://github.com/davidhallac/TVGL.git\n",
    "```\n",
    "Its requirements are [`cvxpy`](http://www.cvxpy.org/en/latest/install/index.html) and [`snap`](https://snap.stanford.edu/snappy/) installed. \n",
    "\n",
    "2. Modify the line 76 of ./TVGL/TVGL.py (ie, `return thetaSet`) with \n",
    "```\n",
    "return thetaSet, empCovSet, gvx.status, gvx\n",
    "```\n",
    "3. Add after the line 454 of ./TVGL/inferGraphL2.py (and other norms if required)\n",
    "```\n",
    "self.n_iter_ = num_iterations\n",
    "```\n",
    "\n",
    "* REGAIN\n",
    "Of course, first of all you should download and install the `regain` package (our method). If you haven't done it yet, do it now!\n",
    "\n",
    "```\n",
    "conda install -c fdtomasi regain\n",
    "```\n",
    "or\n",
    "```\n",
    "pip install regain\n",
    "```\n",
    "\n",
    "Or, you have the source code, `mv` to the `regain` folder, then\n",
    "```\n",
    "python setup.py install\n",
    "```\n",
    "or\n",
    "```\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "and that's it. Now you are good to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import product\n",
    "from sklearn.utils.extmath import squared_norm\n",
    "from sklearn.covariance import GraphLasso, empirical_covariance\n",
    "from sklearn.datasets.base import Bunch\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "\n",
    "from regain import datasets\n",
    "from regain import prox\n",
    "from regain import utils\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performances of the different algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TVGL_path = '~/src/TVGL'\n",
    "from performance_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting 1\n",
    "alpha = 0.45  #0.0025\n",
    "tau = 3\n",
    "beta = 50  # 1000\n",
    "eta = 10\n",
    "\n",
    "n_samples = 100\n",
    "n_dim_lat = 20\n",
    "T = 10\n",
    "n_dim_obs = 100\n",
    "\n",
    "k = (n_dim_obs, T)\n",
    "\n",
    "np.random.seed(20)\n",
    "\n",
    "# mode = 'norm'\n",
    "data = {\n",
    "    (dim, T): datasets.make_dataset(\n",
    "        #     mode=mode,\n",
    "        update_theta='l2',\n",
    "        update_ell='l2',\n",
    "        normalize_starting_matrices=True,\n",
    "        n_samples=n_samples,\n",
    "        n_dim_lat=n_dim_lat,\n",
    "        n_dim_obs=dim,\n",
    "        T=T,\n",
    "        epsilon=1e-1,\n",
    "        proportional=True,\n",
    "        degree=2,\n",
    "        keep_sparsity=True)\n",
    "    for dim in [n_dim_obs]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting 2\n",
    "alpha = .43\n",
    "tau = 1.9\n",
    "beta = 1\n",
    "eta = 2\n",
    "\n",
    "n_samples = 100  # 500\n",
    "n_dim_lat = 5\n",
    "T = 100\n",
    "n_dim_obs = 50\n",
    "\n",
    "k = (n_dim_obs, T)\n",
    "\n",
    "np.random.seed(20)\n",
    "# data = {(dim, T) : datasets.generate_dataset(\n",
    "#     mode='fixed', n_samples=n_samples, n_dim_lat=n_dim_lat, n_dim_obs=dim,  T=T, epsilon=1e-3, degree=3)\n",
    "#     for dim in n_dims}\n",
    "data = {\n",
    "    (dim, T): datasets.make_dataset(\n",
    "        update_ell='l1', update_theta='l1',\n",
    "        n_samples=n_samples, n_dim_lat=n_dim_lat, n_dim_obs=dim,\n",
    "        T=T, epsilon=1e-1, proportional=False, degree=2, keep_sparsity=True)\n",
    "    for dim in [n_dim_obs]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "K = data[k].thetas\n",
    "\n",
    "print([(i != 0).sum() for i in K])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data[k].thetas == 0).sum() / (n_dim_obs**2 * T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    [\n",
    "        np.linalg.norm(data[k].thetas[i] - data[k].thetas[i + 1])\n",
    "        for i in range(T - 1)\n",
    "    ])\n",
    "print(\n",
    "    [\n",
    "        np.linalg.norm(data[k].ells[i] - data[k].ells[i + 1])\n",
    "        for i in range(T - 1)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataframe for results\n",
    "n_dims = [n_dim_obs]\n",
    "n_times = [T]\n",
    "methods = [\n",
    "    'LTGL ($\\ell_2^2$)', 'LTGL ($\\ell_1$)', 'GL', 'LVGLASSO',\n",
    "    'TVGL ($\\ell_2^2$)', 'TVGL ($\\ell_1$)'\n",
    "]\n",
    "scores = sorted(\n",
    "    [\n",
    "        \"MSE_precision\", \"MSE_observed\", \"MSE_latent\", 'estimator',\n",
    "        \"mean_rank_error\", 'time', 'iterations', 'precision', 'recall',\n",
    "        'accuracy', 'balanced_accuracy', 'f1', 'npv', 'prevalence',\n",
    "        'miss_rate', 'likelihood', 'specificity', 'plr', 'nlr'\n",
    "    ])\n",
    "\n",
    "cols = pd.MultiIndex.from_product([scores, n_dims], names=('score', 'dim'))\n",
    "rows = pd.MultiIndex.from_product([methods, n_times], names=('method', 'time'))\n",
    "\n",
    "dff = pd.DataFrame(columns=cols, index=rows)\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# setting 1\n",
    "alpha = 0.361  #289 #0.0025\n",
    "tau = 1.12\n",
    "beta = 5e2\n",
    "eta = 5\n",
    "alpha_chandri_setting_1 = 0.29\n",
    "\n",
    "# # setting 2\n",
    "# alpha = .43 #0.0025\n",
    "# tau = 1.99\n",
    "# beta = 2\n",
    "# eta = 20\n",
    "# alpha_gl_setting_2 = .35\n",
    "\n",
    "for i, (k, res) in enumerate(sorted(data.items())[:5]):\n",
    "    dim = k[0]\n",
    "    print(\"Start with: dim=%d, T=%d (it %d)\" % (k[0], k[1], i))\n",
    "    data_list = res.data\n",
    "    K = res.thetas\n",
    "    K_obs = res.thetas_observed\n",
    "    ells = res.ells\n",
    "    data_grid = np.array(data_list).transpose(\n",
    "        1, 2, 0)  # to use it later for grid search\n",
    "\n",
    "    print(\"starting LTGL l1...\\r\", end='')\n",
    "    res_l = ltgl_results(\n",
    "        res.X, res.y, K, K_obs, ells, alpha=alpha, beta=beta, verbose=0,\n",
    "        max_iter=1000, tau=tau, eta=eta, psi='l1', phi='laplacian', tol=1e-5,\n",
    "        rtol=1e-5)\n",
    "    dff.loc[idx['LTGL ($\\ell_1$)', k[1]], idx[:, k[0]]] = [\n",
    "        res_l[x] for x in scores\n",
    "    ]\n",
    "\n",
    "    print(\"starting LTGL l2...\\r\", end='')\n",
    "    res_l = ltgl_results(\n",
    "        res.X, res.y, K, K_obs, ells, alpha=alpha, beta=beta, tau=tau, eta=eta,\n",
    "        psi='laplacian', phi='laplacian', tol=1e-5, rtol=1e-5)\n",
    "    dff.loc[idx['LTGL ($\\ell_2^2$)', k[1]], idx[:, k[0]]] = [\n",
    "        res_l[x] for x in scores\n",
    "    ]\n",
    "\n",
    "    print(\"starting GL ...\\r\", end='')\n",
    "    try:\n",
    "        res = glasso_results(data_grid, K, K_obs, ells, alpha=alpha)\n",
    "        #         res = glasso_results(data_grid, K, K_obs, ells, alpha=alpha_gl_setting_2)\n",
    "\n",
    "        # res = friedman_results(data_grid, K, K_obs, ells, alpha=alpha)\n",
    "        dff.loc[idx['GL', k[1]], idx[:, k[0]]] = [res[x] for x in scores]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    print(\"starting LVGLASSO...\\r\", end='')\n",
    "    #     res_c = chandresekeran_results(data_grid, K, K_obs, ells, tau=tau, alpha=alpha)\n",
    "    res_c = chandresekeran_results(\n",
    "        data_grid, K, K_obs, ells, tau=tau, alpha=alpha_chandri_setting_1)\n",
    "    dff.loc[idx['LVGLASSO', k[1]], idx[:, k[0]]] = [res_c[x] for x in scores]\n",
    "\n",
    "    print(\"starting TVGL L1...\\r\", end='')\n",
    "    res = hallac_results(\n",
    "        data_grid, K, K_obs, ells, beta=beta, alpha=alpha, penalty=1, tvgl_path=TVGL_path)\n",
    "    dff.loc[idx['TVGL ($\\ell_1$)', k[1]], idx[:, k[0]]] = [\n",
    "        res[x] for x in scores\n",
    "    ]\n",
    "\n",
    "    print(\"starting TVGL L22...\\r\", end='')\n",
    "    res = hallac_results(\n",
    "        data_grid, K, K_obs, ells, beta=beta, alpha=alpha, penalty=3, tvgl_path=TVGL_path)\n",
    "    dff.loc[idx['TVGL ($\\ell_2^2$)', k[1]], idx[:, k[0]]] = [\n",
    "        res[x] for x in scores\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = dff.xs(n_dim_obs, level='dim', axis=1).xs(T, level='time')\n",
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "' & '.join(['%.3f' % Decimal(i) for i in mm['MSE_precision']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff[[s for s in scores if s != 'estimator']].to_pickle(\"dff_setting_1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = (\n",
    "    [\n",
    "        np.linalg.matrix_rank(r)\n",
    "        for r in mm.estimator['LTGL ($\\ell_2^2$)'].latent_\n",
    "    ])\n",
    "l2 = (\n",
    "    [\n",
    "        np.linalg.matrix_rank(r)\n",
    "        for r in mm.estimator['LTGL ($\\ell_1$)'].latent_\n",
    "    ])\n",
    "l3 = ([np.linalg.matrix_rank(r) for r in mm.estimator['LVGLASSO'].L])\n",
    "\n",
    "l4 = (\n",
    "    [\n",
    "        np.linalg.matrix_rank(r)\n",
    "        for r in mm.estimator['LTGL ($\\ell_2^2$)'].latent_\n",
    "    ])\n",
    "l5 = (\n",
    "    [\n",
    "        np.linalg.matrix_rank(r)\n",
    "        for r in mm.estimator['LTGL ($\\ell_1$)'].latent_\n",
    "    ])\n",
    "l6 = ([np.linalg.matrix_rank(r) for r in mm.estimator['LVGLASSO'].L])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1, l2, l3, l4, l5, l6 = utils.load_pickle(filename=\"ells.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, sharey=False, figsize=(10, 5), dpi=600)\n",
    "\n",
    "colors = ['white', 'lightblue', 'C7']\n",
    "alpha = 0.95\n",
    "\n",
    "counter = collections.Counter(l1)\n",
    "ax1.bar(\n",
    "    counter.keys(),\n",
    "    np.array(counter.values()) / len(l1), alpha=alpha, width=0.24,\n",
    "    label='LTGL ($\\ell_2^2$)', color=colors[0], edgecolor='k')\n",
    "counter = collections.Counter(l2)\n",
    "ax1.bar(\n",
    "    np.array(counter.keys()) + 0.25,\n",
    "    np.array(counter.values()) / len(l1), alpha=alpha, width=0.24,\n",
    "    label='LTGL ($\\ell_1$)', color=colors[1], edgecolor='k')\n",
    "counter = collections.Counter(l3)\n",
    "ax1.bar(\n",
    "    np.array(counter.keys()) - 0.25,\n",
    "    np.array(counter.values()) / len(l1), alpha=alpha, width=0.24,\n",
    "    label='LVGLASSO', color=colors[2], edgecolor='k')\n",
    "\n",
    "ax1.set_xticks(range(0, 30, 2))\n",
    "#ax1.set_ylim(0,5)\n",
    "ax1.axvline(20, c='r', ls='--')\n",
    "ax1.set_xlabel(r'ranks of L obtained with ($p_2$)')\n",
    "ax1.set_ylabel('frequency')\n",
    "# ax1.set_xscale(\"log\")\n",
    "# ax1.set_xlim([10, 100])\n",
    "ax1.xaxis.label.set_size(15)\n",
    "ax1.yaxis.label.set_size(15)\n",
    "\n",
    "#ax1.legend()\n",
    "# ax0.legend(prop={'size': 10})\n",
    "# ax0.set_title('bars with legend')\n",
    "\n",
    "counter = collections.Counter(l4)\n",
    "ax2.bar(\n",
    "    counter.keys(),\n",
    "    np.array(counter.values()) / len(l4), alpha=alpha, width=0.24,\n",
    "    label='LTGL ($\\ell_2^2$)', color=colors[0], edgecolor='k')\n",
    "counter = collections.Counter(l5)\n",
    "ax2.bar(\n",
    "    np.array(counter.keys()) + 0.25,\n",
    "    np.array(counter.values()) / len(l4), alpha=alpha, width=0.24,\n",
    "    label='LTGL ($\\ell_1$)', color=colors[1], edgecolor='k')\n",
    "counter = collections.Counter(l6)\n",
    "ax2.bar(\n",
    "    np.array(counter.keys()) - 0.25,\n",
    "    np.array(counter.values()) / len(l4), alpha=alpha, width=0.24,\n",
    "    label='LVGLASSO', color=colors[2], edgecolor='k')\n",
    "\n",
    "ax2.set_xticks(range(0, 30, 2))\n",
    "# ax2.set_xlim(2.5,6.7)\n",
    "ax2.set_xlabel(r'ranks of L obtained with ($p_1$)')\n",
    "ax2.set_ylabel('frequency')\n",
    "ax2.xaxis.label.set_size(15)\n",
    "ax2.yaxis.label.set_size(15)\n",
    "ax2.axvline(5, c='r', ls='--')\n",
    "ax1.legend(loc='upper left', fontsize='x-large')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.savefig(\n",
    "    \"ranks_distribution_vertical.pdf\", dpi=600, transparent=True,\n",
    "    bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(10, 2.6), dpi=600)\n",
    "\n",
    "colors = ['white', 'lightblue', 'C7']\n",
    "alpha = 0.5\n",
    "\n",
    "counter = collections.Counter(l1)\n",
    "ax1.plot(\n",
    "    range(len(l1)), l1, alpha=alpha, label='LTGL ($\\ell_2^2$)',\n",
    "    color=colors[0])\n",
    "counter = collections.Counter(l2)\n",
    "ax1.plot(\n",
    "    np.arange(len(l1)) + .2, l2, alpha=alpha, label='LTGL ($\\ell_1$)',\n",
    "    color=colors[1])\n",
    "counter = collections.Counter(l3)\n",
    "ax1.plot(\n",
    "    np.arange(len(l1)) + .4, l3, alpha=alpha, label='LVGLASSO',\n",
    "    color=colors[2])\n",
    "\n",
    "# ax1.set_xticks(range(15,25, 1))\n",
    "#ax1.set_ylim(0,5)\n",
    "ax1.axhline(20, c='r', ls='--')\n",
    "ax1.set_xlabel(r'ranks of L obtained with ($p_2$)')\n",
    "ax1.set_ylabel('frequency')\n",
    "ax1.xaxis.label.set_size(15)\n",
    "ax1.yaxis.label.set_size(15)\n",
    "\n",
    "#ax1.legend()\n",
    "# ax0.legend(prop={'size': 10})\n",
    "# ax0.set_title('bars with legend')\n",
    "\n",
    "counter = collections.Counter(l4)\n",
    "ax2.plot(\n",
    "    range(len(l4)), l4, alpha=alpha, label='LTGL ($\\ell_2^2$)',\n",
    "    color=colors[0])\n",
    "counter = collections.Counter(l5)\n",
    "ax2.plot(\n",
    "    np.arange(len(l4)) + .2, l5, alpha=alpha, label='LTGL ($\\ell_1$)',\n",
    "    color=colors[1])\n",
    "counter = collections.Counter(l6)\n",
    "ax2.plot(\n",
    "    np.arange(len(l4)) + .4, l6, alpha=alpha, label='LVGLASSO',\n",
    "    color=colors[2])\n",
    "\n",
    "# ax2.set_xticks(range(10))\n",
    "# ax2.set_xlim(2.5,6.7)\n",
    "ax2.set_xlabel(r'ranks of L obtained with ($p_1$)')\n",
    "ax2.xaxis.label.set_size(15)\n",
    "ax2.axhline(5, c='r', ls='--')\n",
    "ax1.legend(loc='best', fontsize='large')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
