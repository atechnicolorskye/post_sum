{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate random graphs for clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = [nx.random_regular_graph(d=2, n=10) for i in range(3)]\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=(15,5))\n",
    "colors = ['red', 'blue', 'green']\n",
    "for i,r in enumerate(reps):\n",
    "    nx.draw_circular(r, ax=axs[i], node_color=colors[i])\n",
    "# plt.savefig(\"cluster_representative.png\", transparent=True, dpi=200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 10 graphs per cluster that always have that patter plus some edges \n",
    "\n",
    "graphs = []\n",
    "for r in reps:\n",
    "    for i in range(10):\n",
    "        A = nx.adjacency_matrix(r).todense()\n",
    "        zero= np.where(A==0)\n",
    "        \n",
    "        ixs = np.arange(0, zero[0].size)\n",
    "        np.random.shuffle(ixs)\n",
    "        for _from, _to in zip(zero[0][ixs][:3], zero[1][ixs][:3]):\n",
    "            A[_from, _to] = 1\n",
    "            A[_to, _from] = 1\n",
    "        graphs.append(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    fig, ax = plt.subplots(2, 5, figsize=(15,10))\n",
    "    for row in range(2):\n",
    "        for col in range(5):\n",
    "            G = nx.from_numpy_array(graphs[i*10+row*5+col])\n",
    "            nx.draw_circular(G, ax=ax[row, col], node_color=colors[i])\n",
    "            nx.draw_networkx_edges(reps[i], ax=ax[row, col], pos=nx.circular_layout(reps[i]), edge_color=colors[i])\n",
    "    plt.savefig(\"members_of_cluster_\"+str(i)+\".png\", transparent=True, dpi=200, bbox_inches='tight')\n",
    "    plt.plot()\n",
    "    print(\"----------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for k-means on graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_representative(graphs):\n",
    "    bin_graphs = []\n",
    "    for g in graphs:\n",
    "        g_bin = (g.copy()!=0).astype(int)\n",
    "        bin_graphs.append(g_bin)\n",
    "    sum_graph = np.zeros_like(g_bin)\n",
    "    for g in bin_graphs:\n",
    "        sum_graph += g\n",
    "    return (sum_graph == len(graphs)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distances(graphs, reps):\n",
    "    distances = np.zeros((len(graphs), len(reps)))\n",
    "\n",
    "    for i, g in enumerate(graphs):\n",
    "        for j, r in enumerate(reps):\n",
    "            b_g = (g!=0).astype(int)\n",
    "            b_r = (r!=0).astype(int)\n",
    "            diff = b_r - b_g\n",
    "            how_many_plus = np.where(diff == -1)[0].size/2\n",
    "            how_many_less = np.where(diff == 1)[0].size/2\n",
    "            distances[i,j] = how_many_plus + 2*how_many_less\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "def graph_k_means(graphs, k, max_iter=10):\n",
    "    ixs = np.arange(0, len(graphs))\n",
    "    np.random.shuffle(ixs)\n",
    "    repres = np.array(graphs)[np.array(ixs[:k])]\n",
    "    \n",
    "    labels_prev = [-1]*len(graphs)\n",
    "    for iter_ in range(max_iter):\n",
    "        distances = compute_distances(graphs, repres)\n",
    "        print(distances)\n",
    "        normalized_distances = distances/np.max(distances, axis=1)[:, np.newaxis]\n",
    "        similarities = 1 - normalized_distances\n",
    "        print(similarities)\n",
    "        kernel = similarities.dot(similarities.T)\n",
    "        plt.imshow(kernel)\n",
    "        plt.show()\n",
    "        labels = np.argmin(distances, axis=1)\n",
    "        repres = [get_representative(np.array(graphs)[np.where(labels==v)]) for v in np.unique(labels)]\n",
    "        if np.all(labels == labels_prev):\n",
    "            break\n",
    "        print(labels)\n",
    "        labels_prev = labels.copy()\n",
    "    else:\n",
    "        warnings.warn(\"The algorithm did not converge.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_k_means(graphs, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserimento in EM per inferenza grafi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#un alternativa e' applicare kmeans fino a convergenza per calcolarsiil kernel\n",
    "# computazionalmente e' meno efficiente e non sono sicura sia \"utile\", si puo' sempre provare pero'\n",
    "\n",
    "# traccia della struttura dell'algoritmo definitivo\n",
    "def clustering_inference(X, k, max_iter, add_temporal_similarity_prior=True):\n",
    "    \n",
    "    # fai cose preliminari \n",
    "    # il primo giro e' esterno per inizializzare la situa \n",
    "    # inferisci i grafi senza nessun prior sul kernel --> tutti si assomigliano equamente con tutti\n",
    "    if add_temporal_similarity_prior:\n",
    "        # il kernel iniziale e' un gaussiano con varianza abbastanza stretta\n",
    "\n",
    "    ixs = np.arange(0, len(graphs))\n",
    "    np.random.shuffle(ixs)\n",
    "    repres = np.array(graphs)[np.array(ixs[:k])]\n",
    "    for iter_ in range(max_iter):\n",
    "        \n",
    "        distances = compute_distances(graphs, repres)\n",
    "        similarities = 1 - (distances/np.max(distances, axis=1)[:, np.newaxis])\n",
    "        kernel = similarities.dot(similarities.T)\n",
    "        if add_temporal_similarity_prior:\n",
    "            # aggiungi al kernel la similarita' temporale \n",
    "        plt.imshow(kernel) # se vuoi vedere il kernel risultante \n",
    "        plt.show()\n",
    "        \n",
    "        # ottieni i nuovi rappresentanti\n",
    "        labels = np.argmin(distances, axis=1)\n",
    "        repres = [get_representative(np.array(graphs)[np.where(labels==v)]) for v in np.unique(labels)]\n",
    "        \n",
    "        # ottieni i nuovi grafi dato il kernel\n",
    "        \n",
    "        if condition: # e' stabile quando la likelihood del modello non si muove piu'\n",
    "            break\n",
    "    else:\n",
    "        warnings.warn(\"The algorithm did not converge.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
