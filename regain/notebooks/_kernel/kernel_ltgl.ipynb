{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Latent Variable Time-varying Graphical Lasso\n",
    "More than 1-Markovian!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# from itertools import product\n",
    "# from functools import partial\n",
    "# from sklearn.datasets import make_sparse_spd_matrix\n",
    "# from sklearn.datasets.base import Bunch\n",
    "# from sklearn.utils.extmath import squared_norm\n",
    "# from sklearn.covariance import GraphLasso, empirical_covariance\n",
    "# from sklearn.datasets.base import Bunch\n",
    "# from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "from sklearn.gaussian_process import kernels\n",
    "\n",
    "from regain import datasets\n",
    "# from regain.covariance import time_graph_lasso_; reload(time_graph_lasso_);\n",
    "# from regain.covariance import latent_time_graph_lasso_; reload(latent_time_graph_lasso_);\n",
    "# import time\n",
    "\n",
    "# from regain.bayesian import wishart_process_; reload(wishart_process_)\n",
    "# from regain.bayesian import stats; reload(stats)\n",
    "\n",
    "# from regainpr.covariance import kernel_time_graphical_lasso_;\n",
    "# reload(kernel_time_graphical_lasso_);\n",
    "# from regainpr.covariance import kernel_latent_time_graphical_lasso_;\n",
    "# reload(kernel_latent_time_graphical_lasso_);;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# # kernel used to generate data\n",
    "# sns.heatmap(kernels.ExpSineSquared(periodicity=np.pi,\n",
    "#                                       length_scale=2)(np.arange(10)[:,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting 1\n",
    "n_samples = 50\n",
    "T = 10\n",
    "n_dim_obs = 5\n",
    "\n",
    "k = (n_dim_obs, T)\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "data = {\n",
    "    (dim, T): datasets.make_dataset(\n",
    "        mode='sin', shape='smooth', update_theta='l2',\n",
    "        normalize_starting_matrices=False, n_samples=n_samples, n_dim_lat=0,\n",
    "        n_dim_obs=dim, T=T, epsilon=1e-1, proportional=True, degree=2,\n",
    "        keep_sparsity=True)\n",
    "    for dim in [n_dim_obs]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # setting 2 - sample from GPs\n",
    "# n_samples = 50\n",
    "# T = 10\n",
    "# n_dim = 5\n",
    "\n",
    "# np.random.seed(2)\n",
    "\n",
    "# data = [datasets.make_dataset(\n",
    "#     mode='gp', n_samples=n_samples, n_dim_lat=10, n_dim_obs=n_dim,  T=T, epsilon=0.4)\n",
    "#     for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # info on the data set\n",
    "# K = data[0].thetas\n",
    "# print (\"Percentual of non-zero components at each time: {}\".format(\n",
    "#     [(i!=0).sum() / i.size for i in K]))\n",
    "\n",
    "# print (\"Percentual of total non-zero components: {}\".format(\n",
    "#     (K != 0).sum() / (n_dim_obs ** 2 * T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataframe for results\n",
    "n_dims = range(10)\n",
    "n_times = [T]\n",
    "methods = [\n",
    "    'TGL', 'KTGL-exp', 'KTGL-rbf', 'LTGL', 'KLTGL-exp', 'KLTGL-rbf', 'WP'\n",
    "]\n",
    "scores = sorted(\n",
    "    [\n",
    "        \"MSE_precision\", \"MSE_observed\", \"MSE_latent\", 'estimator',\n",
    "        \"mean_rank_error\", 'time', 'iterations', 'precision', 'recall',\n",
    "        'accuracy', 'balanced_accuracy', 'f1', 'npv', 'prevalence',\n",
    "        'miss_rate', 'likelihood', 'specificity', 'plr', 'nlr'\n",
    "    ])\n",
    "\n",
    "cols = pd.MultiIndex.from_product([scores, n_dims], names=('score', 'dim'))\n",
    "rows = pd.MultiIndex.from_product([methods, n_times], names=('method', 'time'))\n",
    "\n",
    "df = pd.DataFrame(columns=cols, index=rows)\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "res = data[(n_dim_obs, T)]\n",
    "\n",
    "data_list = res.data\n",
    "K = res.thetas\n",
    "K_obs = res.thetas_observed\n",
    "ells = res.ells\n",
    "# to use it later for grid search\n",
    "data_grid = np.array(data_list).transpose(1, 2, 0)\n",
    "T = data_list.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ticc.TICC_solver import TICC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('MacOSX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting 1\n",
    "n_samples = 100\n",
    "T = 5\n",
    "n_dim_obs = 20\n",
    "\n",
    "k = (n_dim_obs, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regain.datasets import kernels\n",
    "data = kernels.make_cluster_representative(\n",
    "    n_dim=n_dim_obs, n_clusters=3, T=T, n_samples=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = TICC(window_size=n_samples, number_of_clusters=3)\n",
    "labels_, clusts = mdl.fit(data.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.id_cluster.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(clusts[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GaussianMixture(n_components=5).fit(mdl.complete_D_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run kltgl_performance.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta = 0.5\n",
    "# rng = np.full(T-1, 1000)\n",
    "# kernel_phi = np.diag(rng,1) +np.diag(rng,-1) + np.eye(T)\n",
    "# kernel_phi = np.full((T ,T), 1000)\n",
    "\n",
    "from kltgl_performance import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run_results(data[:2], dff, scores)\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "for i, res in enumerate(data):\n",
    "    # dim = k[0]\n",
    "    data_list = res.data\n",
    "    K = res.thetas\n",
    "    K_obs = res.thetas_observed\n",
    "    ells = res.ells\n",
    "    # to use it later for grid search\n",
    "    data_grid = np.array(data_list).transpose(1, 2, 0)\n",
    "    T = data_list.shape[0]\n",
    "    print(\"Start with: dim=%d, T=%d (it %d)\" % (data_list.shape[-1], T, i))\n",
    "\n",
    "    # print(\"starting TGL ...\\r\", end='')\n",
    "    # res = tgl_results(\n",
    "    #     data_grid,\n",
    "    #     K,\n",
    "    #     K_obs,\n",
    "    #     ells,\n",
    "    #     search_spaces={'alpha': (1e-4, 1e+1, 'log-uniform')},\n",
    "    # )\n",
    "    # df.loc[idx['TGL', T], idx[:, i]] = [res.get(x, None) for x in scores]\n",
    "\n",
    "    # print(\"starting KTGL - exp...\\r\", end='')\n",
    "    # res = ktgl_results(\n",
    "    #     data_list, K, K_obs, ells, search_spaces={\n",
    "    #         'alpha': (1e-4, 1e+1, 'log-uniform'),\n",
    "    #         'ker_param': (1e-4, 1e+1, 'log-uniform')\n",
    "    #     })\n",
    "    # df.loc[idx['KTGL-exp', T], idx[:, i]] = [\n",
    "    #     res.get(x, None) for x in scores\n",
    "    # ]\n",
    "\n",
    "    # print(\"starting KTGL - rbf ...\\r\", end='')\n",
    "    # res = ktgl_results(\n",
    "    #     data_list, K, K_obs, ells, search_spaces={\n",
    "    #         'alpha': (1e-4, 1e+1, 'log-uniform'),\n",
    "    #         'ker_param': (1e-4, 1e+1, 'log-uniform')\n",
    "    #     }, kernel=partial(kernels.RBF))\n",
    "    # df.loc[idx['KTGL-rbf', T], idx[:, i]] = [\n",
    "    #     res.get(x, None) for x in scores\n",
    "    # ]\n",
    "\n",
    "    print(\"starting LTGL ...\\r\", end='')\n",
    "    res = ltgl_results(\n",
    "        data_grid, K, K_obs, ells, search_spaces={\n",
    "            'alpha': (1e-4, 1e+1, 'log-uniform'),\n",
    "            'tau': (1e-4, 1e+1, 'log-uniform'),\n",
    "            'beta': (1e-4, 1e+1, 'log-uniform'),\n",
    "        }, eta=20)\n",
    "    df.loc[idx['LTGL', T], idx[:, i]] = [res.get(x, None) for x in scores]\n",
    "    alpha = res['estimator'].alpha\n",
    "    tau = res['estimator'].tau\n",
    "\n",
    "    print(\"starting KLTGL - exp ...\\r\", end='')\n",
    "    res = kltgl_results(\n",
    "        data_list,\n",
    "        K,\n",
    "        K_obs,\n",
    "        ells,\n",
    "        search_spaces={\n",
    "            # 'alpha': (1e-4, 1e+1, 'log-uniform'),\n",
    "            # 'tau': (1e-4, 1e+1, 'log-uniform'),\n",
    "            'ker_psi_param': (1e-4, 1e+1, 'log-uniform'),\n",
    "        },\n",
    "        alpha=alpha,\n",
    "        tau=tau,\n",
    "        ker_phi_param=20,\n",
    "        kernel_phi=partial(kernels.ConstantKernel))\n",
    "    df.loc[idx['KLTGL-exp', T], idx[:, i]] = [res.get(x, None) for x in scores]\n",
    "\n",
    "    print(\"starting KLTGL - rbf ...\\r\", end='')\n",
    "    res = kltgl_results(\n",
    "        data_list,\n",
    "        K,\n",
    "        K_obs,\n",
    "        ells,\n",
    "        search_spaces={\n",
    "            # 'alpha': (1e-4, 1e+1, 'log-uniform'),\n",
    "            # 'tau': (1e-4, 1e+1, 'log-uniform'),\n",
    "            'ker_psi_param': (1e-4, 1e+1, 'log-uniform'),\n",
    "        },\n",
    "        alpha=alpha,\n",
    "        tau=tau,\n",
    "        ker_phi_param=20,\n",
    "        kernel_phi=partial(kernels.ConstantKernel),\n",
    "        kernel_psi=partial(kernels.RBF),\n",
    "    )\n",
    "    df.loc[idx['KLTGL-rbf', T], idx[:, i]] = [res.get(x, None) for x in scores]\n",
    "\n",
    "    # print(\"starting WP ...\\r\", end='')\n",
    "    # res = wp_results(data_list, K)\n",
    "    # df.loc[idx['WP', T], idx[:, i]] = [res.get(x, None) for x in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_mean_std = pd.DataFrame()\n",
    "for s in scores:\n",
    "    dff_mean_std[\"%s_mean\" % s] = df[s].mean(axis=1)\n",
    "    dff_mean_std[\"%s_std\" % s] = df[s].std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_mean_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mm = dff.xs(n_dim_obs, level='dim', axis=1).xs(T, level='time')\n",
    "mm = dff_mean_std.xs(T, level='time')\n",
    "# mm['likelihood']\n",
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = mm[[\n",
    "    \"f1_mean\", \"accuracy_mean\", \"mean_rank_error_mean\", \"MSE_precision_mean\",\n",
    "    \"time_mean\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from decimal import Decimal\n",
    "\n",
    "\n",
    "def highlight_max(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    print(s.name, any([s.name.startswith(i) for i in [\"f1\", \"accuracy\"]]))\n",
    "\n",
    "    m = s.max() if any([s.name.startswith(i)\n",
    "                        for i in [\"f1\", \"accuracy\"]]) else s.min()\n",
    "    is_max = s == m\n",
    "\n",
    "    s_ = s.copy()\n",
    "    s_[is_max] = '\\textbf{%s}' % (\n",
    "        '%.3f' % Decimal(m) if isinstance(m, float) else m)\n",
    "    return s_\n",
    "\n",
    "\n",
    "path = \"/home/fede/Dropbox (DIBRIS)/projects/graphical models in time/kernel LTGL/exps\"\n",
    "tmp.apply(highlight_max).fillna(\"-\").to_latex(\n",
    "    os.path.join(path, \"results_mean_10latent_50dim_21jan.tex\"),\n",
    "    float_format=lambda x: '%.3f' % x, escape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = kernel_time_graph_lasso_.KernelTimeGraphLasso(\n",
    "    time_on_axis='last', assume_centered=0, verbose=0, rtol=1e-5, tol=1e-5,\n",
    "    max_iter=500, rho=1. / np.sqrt(data_grid.shape[0]),\n",
    "    update_rho_options=dict(mu=5))\n",
    "mdl.fit(data_grid)\n",
    "mdl.score(data_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(data_list)\n",
    "y = np.array([np.ones(x.shape[0]) * i\n",
    "              for i, x in enumerate(data_list)]).flatten().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reload(prox)\n",
    "reload(time_graph_lasso_)\n",
    "reload(kernel_time_graph_lasso_)\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from skopt.optimizer import optimizer\n",
    "reload(optimizer)\n",
    "from skopt import searchcv\n",
    "reload(searchcv)\n",
    "from skopt.space import Categorical\n",
    "\n",
    "\n",
    "# include below until https://github.com/scikit-optimize/scikit-optimize/issues/718 is resolved\n",
    "class BayesSearchCV(searchcv.BayesSearchCV):\n",
    "    def _run_search(self, x):\n",
    "        raise BaseException('Use newer skopt')\n",
    "\n",
    "\n",
    "mdl = kernel_time_graph_lasso_.NewKernelTimeGraphLasso(\n",
    "    alpha=0.5, psi='laplacian', assume_centered=0, verbose=0, rtol=1e-5,\n",
    "    tol=1e-5, max_iter=500, rho=1. / np.sqrt(data_grid.shape[0]),\n",
    "    update_rho_options=dict(mu=5),\n",
    "    kernel=partial(kernels.ExpSineSquared, periodicity=np.pi), length_scale=2)\n",
    "\n",
    "bscv = BayesSearchCV(\n",
    "    mdl,\n",
    "    search_spaces={\n",
    "        'alpha': (1e-4, 1e+1, 'log-uniform'),\n",
    "        'length_scale': (1e-4, 1e+1, 'log-uniform'),\n",
    "        #         'kernel': Categorical([partial(kernels.ExpSineSquared, periodicity=np.pi),\n",
    "        #                                kernels.RBF]),  # categorical parameter\n",
    "    },\n",
    "    n_iter=50,\n",
    "    n_points=3,\n",
    "    cv=StratifiedKFold(3))\n",
    "\n",
    "bscv.fit(X, y)\n",
    "bscv.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reload(wishart_process_)\n",
    "wp = wishart_process_.WishartProcess(time_on_axis='first',\n",
    "                                     verbose=True).fit(data_list)\n",
    "\n",
    "wp.likelihood(wp.D_map)\n",
    "\n",
    "wp.loglikes_after_burnin.max()\n",
    "\n",
    "wp.store_precision = True\n",
    "\n",
    "wp.score(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = dff.xs(n_dim_obs, level='dim', axis=1).xs(T, level='time')\n",
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.abs(\n",
    "    dff.estimator[100]['TGL'][10].precision_ -\n",
    "    dff.estimator[100]['KTGL'][10].precision_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "' & '.join(['%.3f' % Decimal(i) for i in mm['MSE_precision']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff[[s for s in scores if s != 'estimator']].to_pickle(\"dff_setting_1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = (\n",
    "    [\n",
    "        np.linalg.matrix_rank(r)\n",
    "        for r in mm.estimator['LTGL ($\\ell_2^2$)'].latent_\n",
    "    ])\n",
    "l2 = (\n",
    "    [\n",
    "        np.linalg.matrix_rank(r)\n",
    "        for r in mm.estimator['LTGL ($\\ell_1$)'].latent_\n",
    "    ])\n",
    "l3 = ([np.linalg.matrix_rank(r) for r in mm.estimator['LVGLASSO'].L])\n",
    "\n",
    "l4 = (\n",
    "    [\n",
    "        np.linalg.matrix_rank(r)\n",
    "        for r in mm.estimator['LTGL ($\\ell_2^2$)'].latent_\n",
    "    ])\n",
    "l5 = (\n",
    "    [\n",
    "        np.linalg.matrix_rank(r)\n",
    "        for r in mm.estimator['LTGL ($\\ell_1$)'].latent_\n",
    "    ])\n",
    "l6 = ([np.linalg.matrix_rank(r) for r in mm.estimator['LVGLASSO'].L])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1, l2, l3, l4, l5, l6 = utils.load_pickle(filename=\"ells.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, sharey=False, figsize=(10, 5), dpi=600)\n",
    "\n",
    "colors = ['white', 'lightblue', 'C7']\n",
    "alpha = 0.95\n",
    "\n",
    "counter = collections.Counter(l1)\n",
    "ax1.bar(\n",
    "    counter.keys(),\n",
    "    np.array(counter.values()) / len(l1), alpha=alpha, width=0.24,\n",
    "    label='LTGL ($\\ell_2^2$)', color=colors[0], edgecolor='k')\n",
    "counter = collections.Counter(l2)\n",
    "ax1.bar(\n",
    "    np.array(counter.keys()) + 0.25,\n",
    "    np.array(counter.values()) / len(l1), alpha=alpha, width=0.24,\n",
    "    label='LTGL ($\\ell_1$)', color=colors[1], edgecolor='k')\n",
    "counter = collections.Counter(l3)\n",
    "ax1.bar(\n",
    "    np.array(counter.keys()) - 0.25,\n",
    "    np.array(counter.values()) / len(l1), alpha=alpha, width=0.24,\n",
    "    label='LVGLASSO', color=colors[2], edgecolor='k')\n",
    "\n",
    "ax1.set_xticks(range(0, 30, 2))\n",
    "#ax1.set_ylim(0,5)\n",
    "ax1.axvline(20, c='r', ls='--')\n",
    "ax1.set_xlabel(r'ranks of L obtained with ($p_2$)')\n",
    "ax1.set_ylabel('frequency')\n",
    "# ax1.set_xscale(\"log\")\n",
    "# ax1.set_xlim([10, 100])\n",
    "ax1.xaxis.label.set_size(15)\n",
    "ax1.yaxis.label.set_size(15)\n",
    "\n",
    "#ax1.legend()\n",
    "# ax0.legend(prop={'size': 10})\n",
    "# ax0.set_title('bars with legend')\n",
    "\n",
    "counter = collections.Counter(l4)\n",
    "ax2.bar(\n",
    "    counter.keys(),\n",
    "    np.array(counter.values()) / len(l4), alpha=alpha, width=0.24,\n",
    "    label='LTGL ($\\ell_2^2$)', color=colors[0], edgecolor='k')\n",
    "counter = collections.Counter(l5)\n",
    "ax2.bar(\n",
    "    np.array(counter.keys()) + 0.25,\n",
    "    np.array(counter.values()) / len(l4), alpha=alpha, width=0.24,\n",
    "    label='LTGL ($\\ell_1$)', color=colors[1], edgecolor='k')\n",
    "counter = collections.Counter(l6)\n",
    "ax2.bar(\n",
    "    np.array(counter.keys()) - 0.25,\n",
    "    np.array(counter.values()) / len(l4), alpha=alpha, width=0.24,\n",
    "    label='LVGLASSO', color=colors[2], edgecolor='k')\n",
    "\n",
    "ax2.set_xticks(range(0, 30, 2))\n",
    "# ax2.set_xlim(2.5,6.7)\n",
    "ax2.set_xlabel(r'ranks of L obtained with ($p_1$)')\n",
    "ax2.set_ylabel('frequency')\n",
    "ax2.xaxis.label.set_size(15)\n",
    "ax2.yaxis.label.set_size(15)\n",
    "ax2.axvline(5, c='r', ls='--')\n",
    "ax1.legend(loc='upper left', fontsize='x-large')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "f.savefig(\n",
    "    \"ranks_distribution_vertical.pdf\", dpi=600, transparent=True,\n",
    "    bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(10, 2.6), dpi=600)\n",
    "\n",
    "colors = ['white', 'lightblue', 'C7']\n",
    "alpha = 0.5\n",
    "\n",
    "counter = collections.Counter(l1)\n",
    "ax1.plot(\n",
    "    range(len(l1)), l1, alpha=alpha, label='LTGL ($\\ell_2^2$)',\n",
    "    color=colors[0])\n",
    "counter = collections.Counter(l2)\n",
    "ax1.plot(\n",
    "    np.arange(len(l1)) + .2, l2, alpha=alpha, label='LTGL ($\\ell_1$)',\n",
    "    color=colors[1])\n",
    "counter = collections.Counter(l3)\n",
    "ax1.plot(\n",
    "    np.arange(len(l1)) + .4, l3, alpha=alpha, label='LVGLASSO',\n",
    "    color=colors[2])\n",
    "\n",
    "# ax1.set_xticks(range(15,25, 1))\n",
    "#ax1.set_ylim(0,5)\n",
    "ax1.axhline(20, c='r', ls='--')\n",
    "ax1.set_xlabel(r'ranks of L obtained with ($p_2$)')\n",
    "ax1.set_ylabel('frequency')\n",
    "ax1.xaxis.label.set_size(15)\n",
    "ax1.yaxis.label.set_size(15)\n",
    "\n",
    "#ax1.legend()\n",
    "# ax0.legend(prop={'size': 10})\n",
    "# ax0.set_title('bars with legend')\n",
    "\n",
    "counter = collections.Counter(l4)\n",
    "ax2.plot(\n",
    "    range(len(l4)), l4, alpha=alpha, label='LTGL ($\\ell_2^2$)',\n",
    "    color=colors[0])\n",
    "counter = collections.Counter(l5)\n",
    "ax2.plot(\n",
    "    np.arange(len(l4)) + .2, l5, alpha=alpha, label='LTGL ($\\ell_1$)',\n",
    "    color=colors[1])\n",
    "counter = collections.Counter(l6)\n",
    "ax2.plot(\n",
    "    np.arange(len(l4)) + .4, l6, alpha=alpha, label='LVGLASSO',\n",
    "    color=colors[2])\n",
    "\n",
    "# ax2.set_xticks(range(10))\n",
    "# ax2.set_xlim(2.5,6.7)\n",
    "ax2.set_xlabel(r'ranks of L obtained with ($p_1$)')\n",
    "ax2.xaxis.label.set_size(15)\n",
    "ax2.axhline(5, c='r', ls='--')\n",
    "ax1.legend(loc='best', fontsize='large')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(\n",
    "    [[1, 3], [2, 4]], index=[\"exp-sin\", 'RBF'],\n",
    "    columns=['latent', 'no latent'])\n",
    "df.index.name = 'kernel'\n",
    "df.to_latex(\"/home/fede/Downloads/table.tex\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
