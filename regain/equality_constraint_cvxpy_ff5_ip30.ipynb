{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import multivariate_normal as mvnorm\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter,\n",
    "                               AutoMinorLocator)\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "%matplotlib inline\n",
    "\n",
    "import pdb, time\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardised Fama French 5 to industry portfolio 30\n",
    "# Import data\n",
    "data = pd.read_pickle(\"/Users/sikai/Downloads/ff5_30_nonsmooth_standard_4000_draws.pkl\")\n",
    "\n",
    "# # Restrict to 100 time points\n",
    "X = data[10:13].transpose(2, 1, 0)\n",
    "X_cov = np.einsum('ijkl,jmkl->imkl', np.expand_dims(X, 1), np.expand_dims(X, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dimensions, _, n_samples, time_steps = X_cov.shape\n",
    "emp_inv = []\n",
    "for i in range(time_steps):\n",
    "    emp_inv.append(np.linalg.inv(np.mean(X_cov[:, :, :, i], 2)))\n",
    "emp_inv = np.array(emp_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from regain.covariance import TaylorEqualTimeGraphicalLasso, TimeGraphicalLasso\n",
    "tic = time.perf_counter()\n",
    "tgl_tp = TaylorEqualTimeGraphicalLasso(max_iter=10000, loss='LL', c_level=0.2, theta=0.5, rho=1e3, div=2, psi=\"laplacian\")\n",
    "emp_inv_score_tp, baseline_score_tp, fit_score_tp, pre_tp = tgl_tp.fit_cov(X_cov).eval_cov_pre() \n",
    "toc = time.perf_counter()\n",
    "print('Running Time :{}'.format(toc - tic))\n",
    "# min_pre_tp = np.amin(np.abs(pre_tp[pre_tp != 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from regain.covariance import TaylorProxTimeGraphicalLasso, TimeGraphicalLasso\n",
    "tic = time.perf_counter()\n",
    "tgl_tp = TaylorProxTimeGraphicalLasso(max_iter=20000, loss='LL', c_level=0.2, rho=1e3, theta=0.5, tol=1e-4, rtol=1e-4, psi=\"laplacian\")\n",
    "emp_inv_score_tp, baseline_score_tp, fit_score_tp, pre_tp = tgl_tp.fit_cov(X_cov).eval_cov_pre() \n",
    "toc = time.perf_counter()\n",
    "print('Running Time :{}'.format(toc - tic))\n",
    "# min_pre_tp = np.amin(np.abs(pre_tp[pre_tp != 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regain.norm import l1_od_norm\n",
    "from regain.validation import check_norm_prox\n",
    "psi, prox_psi, psi_node_penalty = check_norm_prox(tgl_tp.psi)\n",
    "\n",
    "def penalty_objective(Z_0, Z_1, Z_2, psi, theta):\n",
    "    \"\"\"Penalty-only objective function for time-varying graphical LASSO.\"\"\"\n",
    "    return theta * sum(map(l1_od_norm, Z_0)) + (1 - theta) * sum(map(psi, Z_2 - Z_1))\n",
    "\n",
    "pre_tp_thres = {}\n",
    "fit_score_tp_thres = {}\n",
    "for i in [1e-4, 1e-6, 0]:\n",
    "    pre_tp_thres[i] = np.array([k * (np.abs(k) >= i) for k in pre_tp])\n",
    "    tgl_tp.precision_ = pre_tp_thres[i]\n",
    "    emp_inv_score, baseline_score, fit_score_tp_thres[i], _ = tgl_tp.eval_cov_pre() \n",
    "    print(penalty_objective(pre_tp_thres[i], pre_tp_thres[i][:-1], pre_tp_thres[i][1:], psi, tgl_tp.theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"tp_sol_ff5_ip30_10000_max_2_mult_2_l2.npy\", pre_tp)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from regain.covariance import InequalityTimeGraphicalLasso, TimeGraphicalLasso\n",
    "tic = time.perf_counter()\n",
    "tgl = InequalityTimeGraphicalLasso(max_iter=20000, loss='LL', c_level=0.2, c_prox='grad', rho=5e3, theta=0.5, psi=\"laplacian\")\n",
    "emp_inv_score_grad, baseline_score_grad, fit_score_grad, pre_grad = tgl.fit_cov(X_cov).eval_cov_pre() \n",
    "toc = time.perf_counter()\n",
    "print('Running Time :{}'.format(toc - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /Users/sikai/Dropbox/Research/post_sum/code/regain/regain/covariance/cvx_tvgl.py(155)cvx_inequality_time_graphical_lasso()\n",
      "-> constraints = [(cp.sum(cp.multiply(K[t], S[t])) - cp.log_det(K[t]) <= C[t]) for t in range(T)]\n",
      "(Pdb) objective\n",
      "Minimize(Expression(CONVEX, NONNEGATIVE, ()))\n",
      "(Pdb) n\n",
      "> /Users/sikai/Dropbox/Research/post_sum/code/regain/regain/covariance/cvx_tvgl.py(164)cvx_inequality_time_graphical_lasso()\n",
      "-> prob = cp.Problem(objective, constraints)\n",
      "(Pdb) n\n",
      "> /Users/sikai/Dropbox/Research/post_sum/code/regain/regain/covariance/cvx_tvgl.py(166)cvx_inequality_time_graphical_lasso()\n",
      "-> prob.solve(solver=cp.MOSEK, verbose=True)\n",
      "(Pdb) prob.value\n",
      "(Pdb) print(prob.value)\n",
      "None\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c5b07a446189>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtgl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCVXInequalityTimeGraphicalLasso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'LL'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"laplacian\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0memp_inv_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_cvx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_cov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_cov_pre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running Time :{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoc\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/Research/post_sum/code/regain/regain/covariance/cvx_tvgl.py\u001b[0m in \u001b[0;36mfit_cov\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msam_inv_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msam_inv_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memp_cov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/Research/post_sum/code/regain/regain/covariance/cvx_tvgl.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, emp_cov)\u001b[0m\n\u001b[1;32m    287\u001b[0m         out = cvx_inequality_time_graphical_lasso(\n\u001b[1;32m    288\u001b[0m               \u001b[0memp_cov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memp_inv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m               theta=self.theta, psi=self.psi, gamma=self.gamma, tol=self.tol)\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/Research/post_sum/code/regain/regain/covariance/cvx_tvgl.py\u001b[0m in \u001b[0;36mcvx_inequality_time_graphical_lasso\u001b[0;34m(S, K_init, max_iter, loss, C, theta, psi, gamma, tol)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProblem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;31m# prob.solve(solver=cp.SCS, max_iters=np.int(max_iter), eps=tol, verbose=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMOSEK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/Research/post_sum/code/regain/regain/covariance/cvx_tvgl.py\u001b[0m in \u001b[0;36mcvx_inequality_time_graphical_lasso\u001b[0;34m(S, K_init, max_iter, loss, C, theta, psi, gamma, tol)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProblem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;31m# prob.solve(solver=cp.SCS, max_iters=np.int(max_iter), eps=tol, verbose=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMOSEK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from regain.covariance import CVXInequalityTimeGraphicalLasso, TimeGraphicalLasso\n",
    "tic = time.perf_counter()\n",
    "tgl = CVXInequalityTimeGraphicalLasso(max_iter=1e4, loss='LL', c_level=0.2, theta=0.5, psi=\"l2\", tol=1e-4)\n",
    "emp_inv_score, baseline_score, fit_score, pre_cvx = tgl.fit_cov(X_cov).eval_cov_pre() \n",
    "toc = time.perf_counter()\n",
    "print('Running Time :{}'.format(toc - tic))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.save(\"mosek_sol_ff5_30_standard_alpha_0.2.npy\", pre_cvx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regain.covariance import CVXInequalityTimeGraphicalLasso, TimeGraphicalLasso\n",
    "pre_cvx = np.load(\"mosek_sol_ff5_30_standard_alpha_0.2.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regain.norm import l1_od_norm\n",
    "from regain.validation import check_norm_prox\n",
    "psi, prox_psi, psi_node_penalty = check_norm_prox(tgl_tp.psi)\n",
    "\n",
    "def penalty_objective(Z_0, Z_1, Z_2, psi, theta):\n",
    "    \"\"\"Penalty-only objective function for time-varying graphical LASSO.\"\"\"\n",
    "    return theta * sum(map(l1_od_norm, Z_0)) + (1 - theta) * sum(map(psi, Z_2 - Z_1))\n",
    "\n",
    "pre = {}\n",
    "fit_score = {}\n",
    "# for i in [1e-2, 1e-3, 1e-4, 1e-6]:\n",
    "for i in [1e-4]:\n",
    "    pre[i] = np.array([k * (np.abs(k) >= i) for k in pre_cvx])\n",
    "    tgl_tp.precision_ = pre[i]\n",
    "    emp_inv_score, baseline_score, fit_score[i], _ = tgl_tp.eval_cov_pre() \n",
    "    print(penalty_objective(pre[i], pre[i][:-1], pre[i][1:], psi, tgl_tp.theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgl = TimeGraphicalLasso(alpha=1., beta=1., mode='admm', rho=1, tol=1e-4,\n",
    "            rtol=1e-4, psi='laplacian', max_iter=3000, verbose=False, assume_centered=False, \n",
    "            return_history=False, update_rho_options=None, compute_objective=True, \n",
    "            stop_at=None, stop_when=1e-4, suppress_warn_list=False, init='empirical')\n",
    "fit_score_, pre_ = tgl.fit_cov(X_cov).eval_cov_pre()   "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "fig.patch.set_facecolor('white')\n",
    "colors = \"rgm\"\n",
    "color_index = 0\n",
    "\n",
    "idx = 50\n",
    "\n",
    "ax.plot(range(X_cov.shape[0] * X_cov.shape[0]), tgl.emp_inv[idx].flatten(), color='k', label=r'Empirical Inverse')\n",
    "for i in [min_pre_tp]:\n",
    "# for i in [1e-2, 1e-3, 1e-4]:\n",
    "    ax.plot(range(X_cov.shape[0] * X_cov.shape[0]), pre[i][idx].flatten(), color='r', alpha=0.5, \n",
    "            label=r'Constraint TGL SCS, Thres = {}'.format(i))\n",
    "# for i in [2.]:    \n",
    "#     ax.plot(range(X_cov.shape[0] * X_cov.shape[0]), res[i][3][idx].flatten(), color='g', alpha=0.5,\n",
    "#             label=r'Constraint TGL ADMM CVX, Div = {}'.format(i))\n",
    "ax.plot(range(X_cov.shape[0] * X_cov.shape[0]), pre_grad[idx].flatten(), color='m', alpha=0.5,\n",
    "        label=r'Constraint TGL ADMM Gradient')\n",
    "ax.plot(range(X_cov.shape[0] * X_cov.shape[0]), pre_tp[idx].flatten(), color='g', alpha=0.5,\n",
    "        label=r'Constraint TGL ADMM Linear')\n",
    "ax.plot(range(X_cov.shape[0] * X_cov.shape[0]), pre_[idx].flatten(), color='y', label=r'Vanilla TGL')\n",
    "\n",
    "\n",
    "fig.legend(fontsize=15)\n",
    "ax.set_ylabel('Values', fontsize=15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.set_xlabel('Entries', fontsize=15)\n",
    "ax.set_title(r'Precisions at t={} for Empirical Inverse, TGL and Constraint TGL SCS/ADMM'.format(idx), fontsize=20)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('pre_{}_{}_{}_admm_relax_taylor.pdf'.format(idx, dim_X, dim_fac))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "fig.patch.set_facecolor('white')\n",
    "colors = \"rgm\"\n",
    "color_index = 0\n",
    "\n",
    "for i in [1e-4]:\n",
    "# for i in [1e-2, 1e-3, 1e-4]:\n",
    "    diff = (pre[i] -  pre_cvx).flatten()\n",
    "    ax.hist(diff, bins=100, color='r', alpha=0.5, \n",
    "            label=r'Constraint TGL SCS, Thres = {}'.format(i))\n",
    "# for i in [2.]:    \n",
    "#     diff = (res[i][3] -  pre_cvx).flatten()\n",
    "#     ax.hist(diff, bins=50, color='g', alpha=0.2,\n",
    "#             label=r'Constraint TGL ADMM CVX, Div = {}'.format(i))\n",
    "diff = (pre_grad -  pre_cvx).flatten()\n",
    "ax.hist(diff, bins=100, color='m', alpha=0.2,\n",
    "        label=r'Constraint TGL ADMM Gradient')\n",
    "diff = (pre_tp_thres[1e-4] -  pre_cvx).flatten()\n",
    "ax.hist(diff, bins=100, color='g', alpha=0.2,\n",
    "        label=r'Constraint TGL ADMM Linear')\n",
    "# diff = (pre_ -  pre_cvx).flatten()\n",
    "# ax.hist(diff, bins=100, color='y', alpha=0.5, \n",
    "#         label=r'Vanilla TGL')\n",
    "\n",
    "fig.legend(fontsize=15)\n",
    "ax.set_ylabel('Counts', fontsize=15)\n",
    "ax.set_xlabel('Values', fontsize=15)\n",
    "major_loc = MultipleLocator(base=0.1)\n",
    "ax.xaxis.set_major_locator(major_loc)\n",
    "ax.set_xlim((-2, 2))\n",
    "# ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.set_title(r'Difference in Precisions for TGL and Constraint TGL SCS/ADMM', fontsize=20)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('pre_diff_hist_{}_{}_taylor.pdf'.format(dim_X, dim_fac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "fig.patch.set_facecolor('white')\n",
    "colors = \"rgb\"\n",
    "color_index = 0\n",
    "plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(\"color\", plt.cm.tab20.colors)\n",
    "\n",
    "ax.plot(range(X_cov.shape[-1]), emp_inv_score_tp, color='k', label=r'Empirical Inverse')\n",
    "ax.plot(range(X_cov.shape[-1]), baseline_score_tp, color='c', label=r'Constraint')\n",
    "for i in [1e-4]:\n",
    "    mean_diff = np.mean(np.array(fit_score[i]) - baseline_score)\n",
    "    ax.plot(range(X_cov.shape[-1]), fit_score[i], color='r', alpha=0.5, \n",
    "#     ax.plot(range(X_cov.shape[-1]), fit_score[i], color=colors[color_index], alpha=0.5, \n",
    "            label=r'Constraint TGL MOSEK, Thres = {}, Mean Diff = {:.3f}'.format(i, mean_diff))\n",
    "    color_index += 1\n",
    "# mean_diff = np.mean(np.array(fit_score_grad) - baseline_score_grad)\n",
    "# ax.plot(range(X_cov.shape[-1]), fit_score_grad, alpha=0.5, color='m',\n",
    "#         label=r'Constraint TGL ADMM Gradient, Mean Diff = {:.3f}'.format(mean_diff))\n",
    "# mean_diff = np.mean(np.array(fit_score_tp) - baseline_score_tp)\n",
    "mean_diff = np.mean(np.array(fit_score_tp_thres[1e-4]) - baseline_score_tp)\n",
    "# ax.plot(range(X_cov.shape[-1]), fit_score_tp, alpha=0.5, color='g',\n",
    "ax.plot(range(X_cov.shape[-1]), fit_score_tp_thres[1e-4], alpha=0.5, color='g',\n",
    "        label=r'Constraint TGL ADMM Linear, Mean Diff = {:.3f}'.format(mean_diff))\n",
    "# mean_diff = np.mean(np.array(fit_score_) - res[1][1])\n",
    "# ax.plot(range(X_cov.shape[-1]), fit_score_, color='y', label=r'Vanilla TGL, Mean Diff = {:.3f}'.format(mean_diff))\n",
    "\n",
    "fig.legend(fontsize=15)\n",
    "ax.set_ylabel('Negative Log Likelihood', fontsize=15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.set_xlabel('Time t', fontsize=15)\n",
    "ax.set_title(r'Negative Log Likelihood for Empirical Inverse, Constraint, TGL and Constraint TGL MOSEK/ADMM', fontsize=20)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('ff5_ip30_40000_diff_like_max_2_mult_3_div_5.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(np.array(fit_score_tp_thres[1e-4]) - baseline_score_tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "fig.patch.set_facecolor('white')\n",
    "colors = \"rgb\"\n",
    "color_index = 0\n",
    "\n",
    "ax.plot(range(X_cov.shape[-1]), [sum(sum(abs(emp_inv[k]) > 0)) for k in range(X_cov.shape[-1])], \n",
    "        color='k', label=r'Empirical Inverse')\n",
    "# for i in [min_pre_tp]:\n",
    "for i in [1e-4]:\n",
    "    supp = [sum(sum(abs(pre[i][t]) > 0)) for t in range(X_cov.shape[-1])]\n",
    "    mean_supp = np.mean(supp)\n",
    "    ax.plot(range(X_cov.shape[-1]), supp, color='r', alpha=0.5, \n",
    "#     ax.plot(range(X_cov.shape[-1]), supp, color=colors[color_index], alpha=0.5, \n",
    "            label=r'Constraint TGL MOSEK, Thres = {}, Mean Supp = {}'.format(i, mean_supp))\n",
    "    color_index += 1\n",
    "# supp = [sum(sum(abs(pre_grad[t]) > 0)) for t in range(X_cov.shape[-1])]\n",
    "# ax.plot(range(X_cov.shape[-1]), supp, color='m', alpha=0.5,\n",
    "#         label=r'Constraint TGL ADMM Gradient, Mean Supp = {:.3f}'.format(np.mean(supp)))\n",
    "supp = [sum(sum(abs(pre_tp_thres[1e-4][t]) > 0)) for t in range(X_cov.shape[-1])]\n",
    "# supp = [sum(sum(abs(pre_tp[t]) > 0)) for t in range(X_cov.shape[-1])]\n",
    "ax.plot(range(X_cov.shape[-1]), supp, color='g', alpha=0.5,\n",
    "        label=r'Constraint TGL ADMM Linear, Mean Supp = {:.3f}'.format(np.mean(supp)))\n",
    "# supp = [sum(sum(abs(pre_[t]) > 0)) for t in range(X_cov.shape[-1])]\n",
    "# ax.plot(range(X_cov.shape[-1]), [sum(sum(abs(pre_[k]) > 0)) for k in range(X_cov.shape[-1])], \n",
    "#         color='y', label=r'Vanilla TGL, , Mean Supp = {:.3f}'.format(np.mean(supp)))\n",
    "\n",
    "\n",
    "fig.legend(fontsize=15)\n",
    "ax.set_ylabel('Support', fontsize=15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.set_xlabel('Time t', fontsize=15)\n",
    "ax.set_title(r'Support for Empirical Inverse, TGL and Constraint TGL MOSEK/ADMM', fontsize=20)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('ff5_ip30_40000_diff_supp_max_2_mult_3_div_5.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "fig.patch.set_facecolor('white')\n",
    "colors = \"rgb\"\n",
    "color_index = 0\n",
    "\n",
    "diff_emp = [norm(emp_inv[t] - emp_inv[t-1], 'fro') for t in range(1, X_cov.shape[-1])]\n",
    "ax.plot(range(1, X_cov.shape[-1]), np.array(diff_emp), alpha=1, color='k', label=r'Empirical Inverse')\n",
    "# for i in [min_pre_tp]:\n",
    "for i in [1e-4]:\n",
    "    diff = [norm(pre[i][t] - pre[i][t-1], 'fro') for t in range(1, X_cov.shape[-1])]\n",
    "    mean_diff = np.mean(diff)\n",
    "    ax.plot(range(1, X_cov.shape[-1]), diff, color='r', alpha=0.5, \n",
    "#     ax.plot(range(1, X_cov.shape[-1]), diff, color=colors[color_index], alpha=0.5, \n",
    "            label=r'Constraint TGL MOSEK, Thres = {}, Mean Diff = {:.3f}'.format(i, mean_diff))\n",
    "    color_index += 1\n",
    "# diff_grad = [norm(pre_grad[t] - pre_grad[t-1], 'fro') for t in range(1, X_cov.shape[-1])]\n",
    "# ax.plot(range(1, X_cov.shape[-1]), diff_grad, color='m', alpha=0.5,\n",
    "#         label=r'Constraint TGL ADMM Gradient, Mean Diff = {:.3f}'.format(np.mean(diff_grad)))\n",
    "diff_grad = [norm(pre_tp_thres[1e-4][t] - pre_tp_thres[1e-4][t-1], 'fro') for t in range(1, X_cov.shape[-1])]\n",
    "# diff_grad = [norm(pre_tp[t] - pre_tp[t-1], 'fro') for t in range(1, X_cov.shape[-1])]\n",
    "ax.plot(range(1, X_cov.shape[-1]), diff_grad, color='g', alpha=0.5,\n",
    "        label=r'Constraint TGL ADMM Linear, Mean Diff = {:.3f}'.format(np.mean(diff_grad)))\n",
    "diff_fit_ = [norm(pre_[t] - pre_[t-1], 'fro') for t in range(1, X_cov.shape[-1])]\n",
    "ax.plot(range(1, X_cov.shape[-1]), np.array(diff_fit_), color='y', alpha=1, \n",
    "        label=r'Vanilla TGL, Mean Diff = {:.3f}'.format(np.mean(diff_fit_)))\n",
    "\n",
    "fig.legend(fontsize=15)\n",
    "ax.set_ylabel('Difference in Frobenius Norm', fontsize=15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.set_xlabel('Time t', fontsize=15)\n",
    "ax.set_title(r'Difference in Frobenius Norm for Empirical Inverse, TGL and Constraint TGL MOSEK/ADMM', fontsize=20)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('ff5_ip30_40000_diff_fro_max_2_mult_3_div_5.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
