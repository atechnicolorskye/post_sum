{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import multivariate_normal as mvnorm\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter,\n",
    "                               AutoMinorLocator)\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "%matplotlib inline\n",
    "\n",
    "import pdb, time\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardised Fama French 5 to industry portfolio 30\n",
    "# Import data\n",
    "data = pd.read_pickle(\"/Users/sikai/Downloads/ff5_30_nonsmooth_standard_4000_draws.pkl\")\n",
    "\n",
    "# # Restrict to 100 time points\n",
    "X = data[10:110].transpose(2, 1, 0)\n",
    "X_cov = np.einsum('ijkl,jmkl->imkl', np.expand_dims(X, 1), np.expand_dims(X, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dimensions, _, n_samples, time_steps = X_cov.shape\n",
    "emp_inv = []\n",
    "for i in range(time_steps):\n",
    "    emp_inv.append(np.linalg.inv(np.mean(X_cov[:, :, :, i], 2)))\n",
    "emp_inv = np.array(emp_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from regain.covariance import GradientEqualTimeGraphicalLasso, TimeGraphicalLasso\n",
    "tic = time.perf_counter()\n",
    "tgl_g = GradientEqualTimeGraphicalLasso(max_iter=10000, loss='LL', c_level=0.2, theta=0.5, rho=1e3, mult=2, weights=None, m=100, eps=2, psi=\"l2\")\n",
    "emp_inv_score_g, baseline_score_g, fit_score_g, pre_g = tgl_g.fit_cov(X_cov).eval_cov_pre() \n",
    "toc = time.perf_counter()\n",
    "print('Running Time :{}'.format(toc - tic))\n",
    "# min_pre_tp = np.amin(np.abs(pre_tp[pre_tp != 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from regain.covariance import TaylorEqualTimeGraphicalLasso, TimeGraphicalLasso\n",
    "tic = time.perf_counter()\n",
    "tgl_tp = TaylorEqualTimeGraphicalLasso(max_iter=10000, loss='LL', c_level=0.2, theta=0.5, rho=1e3, mult=2, weights=None, m=100, eps=2, psi=\"laplacian\")\n",
    "emp_inv_score_tp, baseline_score_tp, fit_score_tp, pre_tp = tgl_tp.fit_cov(X_cov).eval_cov_pre() \n",
    "toc = time.perf_counter()\n",
    "print('Running Time :{}'.format(toc - tic))\n",
    "# min_pre_tp = np.amin(np.abs(pre_tp[pre_tp != 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regain.norm import l1_od_norm\n",
    "from regain.validation import check_norm_prox\n",
    "psi, prox_psi, psi_node_penalty = check_norm_prox(tgl_g.psi)\n",
    "\n",
    "def penalty_objective(Z_0, Z_1, Z_2, psi, theta):\n",
    "    \"\"\"Penalty-only objective function for time-varying graphical LASSO.\"\"\"\n",
    "    return theta * sum(map(l1_od_norm, Z_0)) + (1 - theta) * sum(map(psi, Z_2 - Z_1))\n",
    "\n",
    "pre_g_thres = {}\n",
    "fit_score_g_thres = {}\n",
    "for i in [1e-4, 1e-6, 0]:\n",
    "    pre_g_thres[i] = np.array([k * (np.abs(k) >= i) for k in pre_g])\n",
    "    tgl_g.precision_ = pre_g_thres[i]\n",
    "    emp_inv_score, baseline_score, fit_score_g_thres[i], _ = tgl_g.eval_cov_pre() \n",
    "    print(penalty_objective(pre_g_thres[i], pre_g_thres[i][:-1], pre_g_thres[i][1:], psi, tgl_g.theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regain.norm import l1_od_norm\n",
    "from regain.validation import check_norm_prox\n",
    "psi, prox_psi, psi_node_penalty = check_norm_prox(tgl_tp.psi)\n",
    "\n",
    "def penalty_objective(Z_0, Z_1, Z_2, psi, theta):\n",
    "    \"\"\"Penalty-only objective function for time-varying graphical LASSO.\"\"\"\n",
    "    return theta * sum(map(l1_od_norm, Z_0)) + (1 - theta) * sum(map(psi, Z_2 - Z_1))\n",
    "\n",
    "pre_tp_thres = {}\n",
    "fit_score_tp_thres = {}\n",
    "for i in [1e-4, 1e-6, 0]:\n",
    "    pre_tp_thres[i] = np.array([k * (np.abs(k) >= i) for k in pre_tp])\n",
    "    tgl_tp.precision_ = pre_tp_thres[i]\n",
    "    emp_inv_score, baseline_score, fit_score_tp_thres[i], _ = tgl_tp.eval_cov_pre() \n",
    "    print(penalty_objective(pre_tp_thres[i], pre_tp_thres[i][:-1], pre_tp_thres[i][1:], psi, tgl_tp.theta))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.save(\"grad_sol_ff5_ip30_10000_rho_1e3_mult_1.1_m_100_eps_2_l2.npy\", pre_g)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from regain.covariance import InequalityTimeGraphicalLasso, TimeGraphicalLasso\n",
    "tic = time.perf_counter()\n",
    "tgl = InequalityTimeGraphicalLasso(max_iter=20000, loss='LL', c_level=0.2, c_prox='grad', rho=5e3, theta=0.5, psi=\"laplacian\")\n",
    "emp_inv_score_grad, baseline_score_grad, fit_score_grad, pre_grad = tgl.fit_cov(X_cov).eval_cov_pre() \n",
    "toc = time.perf_counter()\n",
    "print('Running Time :{}'.format(toc - tic))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from regain.covariance import CVXInequalityTimeGraphicalLasso, TimeGraphicalLasso\n",
    "tic = time.perf_counter()\n",
    "tgl = CVXInequalityTimeGraphicalLasso(max_iter=1e4, loss='LL', c_level=0.2, theta=0.5, psi=\"l2\", tol=1e-4)\n",
    "emp_inv_score, baseline_score, fit_score, pre_cvx = tgl.fit_cov(X_cov).eval_cov_pre() \n",
    "toc = time.perf_counter()\n",
    "print('Running Time :{}'.format(toc - tic))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.save(\"mosek_sol_ff5_30_standard_alpha_0.2.npy\", pre_cvx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regain.covariance import CVXInequalityTimeGraphicalLasso, TimeGraphicalLasso\n",
    "pre_cvx = np.load(\"mosek_sol_ff5_30_standard_alpha_0.2.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regain.norm import l1_od_norm\n",
    "from regain.validation import check_norm_prox\n",
    "psi, prox_psi, psi_node_penalty = check_norm_prox(tgl_g.psi)\n",
    "\n",
    "def penalty_objective(Z_0, Z_1, Z_2, psi, theta):\n",
    "    \"\"\"Penalty-only objective function for time-varying graphical LASSO.\"\"\"\n",
    "    return theta * sum(map(l1_od_norm, Z_0)) + (1 - theta) * sum(map(psi, Z_2 - Z_1))\n",
    "\n",
    "pre = {}\n",
    "fit_score = {}\n",
    "# for i in [1e-2, 1e-3, 1e-4, 1e-6]:\n",
    "for i in [1e-4]:\n",
    "    pre[i] = np.array([k * (np.abs(k) >= i) for k in pre_cvx])\n",
    "    tgl_g.precision_ = pre[i]\n",
    "    emp_inv_score, baseline_score, fit_score[i], _ = tgl_g.eval_cov_pre() \n",
    "    print(penalty_objective(pre[i], pre[i][:-1], pre[i][1:], psi, tgl_g.theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgl = TimeGraphicalLasso(alpha=1., beta=1., mode='admm', rho=1, tol=1e-4,\n",
    "            rtol=1e-4, psi='laplacian', max_iter=3000, verbose=False, assume_centered=False, \n",
    "            return_history=False, update_rho_options=None, compute_objective=True, \n",
    "            stop_at=None, stop_when=1e-4, suppress_warn_list=False, init='empirical')\n",
    "fit_score_, pre_ = tgl.fit_cov(X_cov).eval_cov_pre()   "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "fig.patch.set_facecolor('white')\n",
    "colors = \"rgm\"\n",
    "color_index = 0\n",
    "\n",
    "idx = 50\n",
    "\n",
    "ax.plot(range(X_cov.shape[0] * X_cov.shape[0]), tgl.emp_inv[idx].flatten(), color='k', label=r'Empirical Inverse')\n",
    "for i in [min_pre_tp]:\n",
    "# for i in [1e-2, 1e-3, 1e-4]:\n",
    "    ax.plot(range(X_cov.shape[0] * X_cov.shape[0]), pre[i][idx].flatten(), color='r', alpha=0.5, \n",
    "            label=r'Constraint TGL SCS, Thres = {}'.format(i))\n",
    "# for i in [2.]:    \n",
    "#     ax.plot(range(X_cov.shape[0] * X_cov.shape[0]), res[i][3][idx].flatten(), color='g', alpha=0.5,\n",
    "#             label=r'Constraint TGL ADMM CVX, Div = {}'.format(i))\n",
    "ax.plot(range(X_cov.shape[0] * X_cov.shape[0]), pre_grad[idx].flatten(), color='m', alpha=0.5,\n",
    "        label=r'Constraint TGL ADMM Gradient')\n",
    "ax.plot(range(X_cov.shape[0] * X_cov.shape[0]), pre_tp[idx].flatten(), color='g', alpha=0.5,\n",
    "        label=r'Constraint TGL ADMM Linear')\n",
    "ax.plot(range(X_cov.shape[0] * X_cov.shape[0]), pre_[idx].flatten(), color='y', label=r'Vanilla TGL')\n",
    "\n",
    "\n",
    "fig.legend(fontsize=15)\n",
    "ax.set_ylabel('Values', fontsize=15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.set_xlabel('Entries', fontsize=15)\n",
    "ax.set_title(r'Precisions at t={} for Empirical Inverse, TGL and Constraint TGL SCS/ADMM'.format(idx), fontsize=20)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('pre_{}_{}_{}_admm_relax_taylor.pdf'.format(idx, dim_X, dim_fac))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "fig.patch.set_facecolor('white')\n",
    "colors = \"rgm\"\n",
    "color_index = 0\n",
    "\n",
    "for i in [1e-4]:\n",
    "# for i in [1e-2, 1e-3, 1e-4]:\n",
    "    diff = (pre[i] -  pre_cvx).flatten()\n",
    "    ax.hist(diff, bins=100, color='r', alpha=0.5, \n",
    "            label=r'Constraint TGL SCS, Thres = {}'.format(i))\n",
    "# for i in [2.]:    \n",
    "#     diff = (res[i][3] -  pre_cvx).flatten()\n",
    "#     ax.hist(diff, bins=50, color='g', alpha=0.2,\n",
    "#             label=r'Constraint TGL ADMM CVX, Div = {}'.format(i))\n",
    "diff = (pre_grad -  pre_cvx).flatten()\n",
    "ax.hist(diff, bins=100, color='m', alpha=0.2,\n",
    "        label=r'Constraint TGL ADMM Gradient')\n",
    "diff = (pre_tp_thres[1e-4] -  pre_cvx).flatten()\n",
    "ax.hist(diff, bins=100, color='g', alpha=0.2,\n",
    "        label=r'Constraint TGL ADMM Linear')\n",
    "# diff = (pre_ -  pre_cvx).flatten()\n",
    "# ax.hist(diff, bins=100, color='y', alpha=0.5, \n",
    "#         label=r'Vanilla TGL')\n",
    "\n",
    "fig.legend(fontsize=15)\n",
    "ax.set_ylabel('Counts', fontsize=15)\n",
    "ax.set_xlabel('Values', fontsize=15)\n",
    "major_loc = MultipleLocator(base=0.1)\n",
    "ax.xaxis.set_major_locator(major_loc)\n",
    "ax.set_xlim((-2, 2))\n",
    "# ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.set_title(r'Difference in Precisions for TGL and Constraint TGL SCS/ADMM', fontsize=20)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('pre_diff_hist_{}_{}_taylor.pdf'.format(dim_X, dim_fac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "fig.patch.set_facecolor('white')\n",
    "colors = \"rgb\"\n",
    "color_index = 0\n",
    "plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(\"color\", plt.cm.tab20.colors)\n",
    "\n",
    "ax.plot(range(X_cov.shape[-1]), emp_inv_score_g, color='k', label=r'Empirical Inverse')\n",
    "ax.plot(range(X_cov.shape[-1]), baseline_score_g, color='c', label=r'Constraint')\n",
    "for i in [1e-4]:\n",
    "    mean_diff = np.mean(np.array(fit_score[i]) - baseline_score)\n",
    "    ax.plot(range(X_cov.shape[-1]), fit_score[i], color='r', alpha=0.5, \n",
    "#     ax.plot(range(X_cov.shape[-1]), fit_score[i], color=colors[color_index], alpha=0.5, \n",
    "            label=r'Constraint TGL MOSEK, Thres = {}, Mean Diff = {:.3f}'.format(i, mean_diff))\n",
    "    color_index += 1\n",
    "# mean_diff = np.mean(np.array(fit_score_grad) - baseline_score_grad)\n",
    "# ax.plot(range(X_cov.shape[-1]), fit_score_grad, alpha=0.5, color='m',\n",
    "#         label=r'Constraint TGL ADMM Gradient, Mean Diff = {:.3f}'.format(mean_diff))\n",
    "# mean_diff = np.mean(np.array(fit_score_tp) - baseline_score_tp)\n",
    "mean_diff = np.mean(np.array(fit_score_g_thres[1e-4]) - baseline_score_g)\n",
    "# ax.plot(range(X_cov.shape[-1]), fit_score_tp, alpha=0.5, color='g',\n",
    "ax.plot(range(X_cov.shape[-1]), fit_score_g_thres[1e-4], alpha=0.5, color='g',\n",
    "        label=r'Constraint TGL ADMM Gradient, Mean Diff = {:.3f}'.format(mean_diff))\n",
    "# mean_diff = np.mean(np.array(fit_score_tp_thres[1e-4]) - baseline_score_g)\n",
    "# # ax.plot(range(X_cov.shape[-1]), fit_score_tp, alpha=0.5, color='g',\n",
    "# ax.plot(range(X_cov.shape[-1]), fit_score_tp_thres[1e-4], alpha=0.5, color='m',\n",
    "#         label=r'Constraint TGL ADMM Linear, Mean Diff = {:.3f}'.format(mean_diff))\n",
    "\n",
    "# mean_diff = np.mean(np.array(fit_score_) - res[1][1])\n",
    "# ax.plot(range(X_cov.shape[-1]), fit_score_, color='y', label=r'Vanilla TGL, Mean Diff = {:.3f}'.format(mean_diff))\n",
    "\n",
    "fig.legend(fontsize=15)\n",
    "ax.set_ylabel('Negative Log Likelihood', fontsize=15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.set_xlabel('Time t', fontsize=15)\n",
    "ax.set_title(r'Negative Log Likelihood for Empirical Inverse, Constraint, TGL and Constraint TGL MOSEK/ADMM', fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('ff5_ip30_10000_diff_like_indiv.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(np.array(fit_score_g_thres[1e-4]) - baseline_score_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "fig.patch.set_facecolor('white')\n",
    "colors = \"rgb\"\n",
    "color_index = 0\n",
    "\n",
    "ax.plot(range(X_cov.shape[-1]), [sum(sum(abs(emp_inv[k]) > 0)) for k in range(X_cov.shape[-1])], \n",
    "        color='k', label=r'Empirical Inverse')\n",
    "# for i in [min_pre_tp]:\n",
    "for i in [1e-4]:\n",
    "    supp = [sum(sum(abs(pre[i][t]) > 0)) for t in range(X_cov.shape[-1])]\n",
    "    mean_supp = np.mean(supp)\n",
    "    ax.plot(range(X_cov.shape[-1]), supp, color='r', alpha=0.5, \n",
    "#     ax.plot(range(X_cov.shape[-1]), supp, color=colors[color_index], alpha=0.5, \n",
    "            label=r'Constraint TGL MOSEK, Thres = {}, Mean Supp = {}'.format(i, mean_supp))\n",
    "    color_index += 1\n",
    "# supp = [sum(sum(abs(pre_grad[t]) > 0)) for t in range(X_cov.shape[-1])]\n",
    "# ax.plot(range(X_cov.shape[-1]), supp, color='m', alpha=0.5,\n",
    "#         label=r'Constraint TGL ADMM Gradient, Mean Supp = {:.3f}'.format(np.mean(supp)))\n",
    "supp = [sum(sum(abs(pre_g_thres[1e-4][t]) > 0)) for t in range(X_cov.shape[-1])]\n",
    "# supp = [sum(sum(abs(pre_tp[t]) > 0)) for t in range(X_cov.shape[-1])]\n",
    "ax.plot(range(X_cov.shape[-1]), supp, color='g', alpha=0.5,\n",
    "        label=r'Constraint TGL ADMM Gradient, Mean Supp = {:.3f}'.format(np.mean(supp)))\n",
    "# supp = [sum(sum(abs(pre_tp_thres[1e-4][t]) > 0)) for t in range(X_cov.shape[-1])]\n",
    "# supp = [sum(sum(abs(pre_tp[t]) > 0)) for t in range(X_cov.shape[-1])]\n",
    "# ax.plot(range(X_cov.shape[-1]), supp, color='m', alpha=0.5,\n",
    "#         label=r'Constraint TGL ADMM Linear, Mean Supp = {:.3f}'.format(np.mean(supp)))\n",
    "# supp = [sum(sum(abs(pre_[t]) > 0)) for t in range(X_cov.shape[-1])]\n",
    "# ax.plot(range(X_cov.shape[-1]), [sum(sum(abs(pre_[k]) > 0)) for k in range(X_cov.shape[-1])], \n",
    "#         color='y', label=r'Vanilla TGL, , Mean Supp = {:.3f}'.format(np.mean(supp)))\n",
    "\n",
    "\n",
    "fig.legend(fontsize=15)\n",
    "ax.set_ylabel('Support', fontsize=15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.set_xlabel('Time t', fontsize=15)\n",
    "ax.set_title(r'Support for Empirical Inverse, TGL and Constraint TGL MOSEK/ADMM', fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('ff5_ip30_10000_diff_supp_indiv.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "fig.patch.set_facecolor('white')\n",
    "colors = \"rgb\"\n",
    "color_index = 0\n",
    "\n",
    "diff_emp = [norm(emp_inv[t] - emp_inv[t-1], 'fro') for t in range(1, X_cov.shape[-1])]\n",
    "ax.plot(range(1, X_cov.shape[-1]), np.array(diff_emp), alpha=1, color='k', label=r'Empirical Inverse')\n",
    "# for i in [min_pre_tp]:\n",
    "for i in [1e-4]:\n",
    "    diff = [norm(pre[i][t] - pre[i][t-1], 'fro') for t in range(1, X_cov.shape[-1])]\n",
    "    mean_diff = np.mean(diff)\n",
    "    ax.plot(range(1, X_cov.shape[-1]), diff, color='r', alpha=0.5, \n",
    "#     ax.plot(range(1, X_cov.shape[-1]), diff, color=colors[color_index], alpha=0.5, \n",
    "            label=r'Constraint TGL MOSEK, Thres = {}, Mean Diff = {:.3f}'.format(i, mean_diff))\n",
    "    color_index += 1\n",
    "# diff_grad = [norm(pre_grad[t] - pre_grad[t-1], 'fro') for t in range(1, X_cov.shape[-1])]\n",
    "# ax.plot(range(1, X_cov.shape[-1]), diff_grad, color='m', alpha=0.5,\n",
    "#         label=r'Constraint TGL ADMM Gradient, Mean Diff = {:.3f}'.format(np.mean(diff_grad)))\n",
    "diff_grad = [norm(pre_g_thres[1e-4][t] - pre_g_thres[1e-4][t-1], 'fro') for t in range(1, X_cov.shape[-1])]\n",
    "# diff_grad = [norm(pre_tp[t] - pre_tp[t-1], 'fro') for t in range(1, X_cov.shape[-1])]\n",
    "ax.plot(range(1, X_cov.shape[-1]), diff_grad, color='g', alpha=0.5,\n",
    "        label=r'Constraint TGL ADMM Gradient, Mean Diff = {:.3f}'.format(np.mean(diff_grad)))\n",
    "# diff_grad = [norm(pre_tp_thres[1e-4][t] - pre_tp_thres[1e-4][t-1], 'fro') for t in range(1, X_cov.shape[-1])]\n",
    "# # diff_grad = [norm(pre_tp[t] - pre_tp[t-1], 'fro') for t in range(1, X_cov.shape[-1])]\n",
    "# ax.plot(range(1, X_cov.shape[-1]), diff_grad, color='m', alpha=0.5,\n",
    "#         label=r'Constraint TGL ADMM Linear, Mean Diff = {:.3f}'.format(np.mean(diff_grad)))\n",
    "diff_fit_ = [norm(pre_[t] - pre_[t-1], 'fro') for t in range(1, X_cov.shape[-1])]\n",
    "ax.plot(range(1, X_cov.shape[-1]), np.array(diff_fit_), color='y', alpha=1, \n",
    "        label=r'Vanilla TGL, Mean Diff = {:.3f}'.format(np.mean(diff_fit_)))\n",
    "\n",
    "fig.legend(fontsize=15)\n",
    "ax.set_ylabel('Difference in Frobenius Norm', fontsize=15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.set_xlabel('Time t', fontsize=15)\n",
    "ax.set_title(r'Difference in Frobenius Norm for Empirical Inverse, TGL and Constraint TGL MOSEK/ADMM', fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('ff5_ip30_10000_diff_fro_indiv.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "fig.patch.set_facecolor('white')\n",
    "colors = \"rgb\"\n",
    "color_index = 0\n",
    "\n",
    "diff_emp = [np.sum(norm(emp_inv[t] - emp_inv[t-1], axis=1)) for t in range(1, X_cov.shape[-1])]\n",
    "ax.plot(range(1, X_cov.shape[-1]), np.array(diff_emp), alpha=1, color='k', label=r'Empirical Inverse')\n",
    "# for i in [min_pre_tp]:\n",
    "for i in [1e-4]:\n",
    "    diff = [np.sum(norm(pre[i][t] - pre[i][t-1], axis=1)) for t in range(1, X_cov.shape[-1])]\n",
    "    mean_diff = np.mean(diff)\n",
    "    ax.plot(range(1, X_cov.shape[-1]), diff, color='r', alpha=0.5, \n",
    "#     ax.plot(range(1, X_cov.shape[-1]), diff, color=colors[color_index], alpha=0.5, \n",
    "            label=r'Constraint TGL MOSEK, Thres = {}, Mean Diff = {:.3f}'.format(i, mean_diff))\n",
    "    color_index += 1\n",
    "# diff_grad = [norm(pre_grad[t] - pre_grad[t-1], axis=1) for t in range(1, X_cov.shape[-1])]\n",
    "# ax.plot(range(1, X_cov.shape[-1]), diff_grad, color='m', alpha=0.5,\n",
    "#         label=r'Constraint TGL ADMM Gradient, Mean Diff = {:.3f}'.format(np.mean(diff_grad)))\n",
    "diff_grad = [np.sum(norm(pre_g_thres[1e-4][t] - pre_g_thres[1e-4][t-1], axis=1)) for t in range(1, X_cov.shape[-1])]\n",
    "# diff_grad = [norm(pre_tp[t] - pre_tp[t-1], axis=1) for t in range(1, X_cov.shape[-1])]\n",
    "ax.plot(range(1, X_cov.shape[-1]), diff_grad, color='g', alpha=0.5,\n",
    "        label=r'Constraint TGL ADMM Gradient, Mean Diff = {:.3f}'.format(np.mean(diff_grad)))\n",
    "diff_grad = [np.sum(norm(pre_tp_thres[1e-4][t] - pre_tp_thres[1e-4][t-1], axis=1)) for t in range(1, X_cov.shape[-1])]\n",
    "# diff_grad = [norm(pre_tp[t] - pre_tp[t-1], axis=1) for t in range(1, X_cov.shape[-1])]\n",
    "ax.plot(range(1, X_cov.shape[-1]), diff_grad, color='m', alpha=0.5,\n",
    "        label=r'Constraint TGL ADMM Linear, Mean Diff = {:.3f}'.format(np.mean(diff_grad)))\n",
    "diff_fit_ = [np.sum(norm(pre_[t] - pre_[t-1], axis=1)) for t in range(1, X_cov.shape[-1])]\n",
    "ax.plot(range(1, X_cov.shape[-1]), np.array(diff_fit_), color='y', alpha=1, \n",
    "        label=r'Vanilla TGL, Mean Diff = {:.3f}'.format(np.mean(diff_fit_)))\n",
    "\n",
    "fig.legend(fontsize=15)\n",
    "ax.set_ylabel('Difference in L2 Norm', fontsize=15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.set_xlabel('Time t', fontsize=15)\n",
    "ax.set_title(r'Difference in L2 Norm for Empirical Inverse, TGL and Constraint TGL MOSEK/ADMM', fontsize=20)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('ff5_ip30_40000_diff_fro_max_2_mult_3_div_5.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
