{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import multivariate_normal as mvnorm\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "%matplotlib inline\n",
    "\n",
    "import pdb\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "data = pd.read_pickle(\"~/Downloads/integrated_draws_20_5_4.pkl\")\n",
    "n_draws, n_time, dim_X, dim_fac = data['beta'].shape\n",
    "beta = data['beta']\n",
    "X_sd = data['x_sd']\n",
    "\n",
    "# Generate X\n",
    "m_fac = np.zeros((dim_fac))\n",
    "s_fac = np.diag(np.ones((dim_fac)))\n",
    "fac = np.expand_dims(mvnorm(m_fac, s_fac, (n_draws, n_time)), -1)\n",
    "\n",
    "X = np.matmul(beta, fac).squeeze()\n",
    "\n",
    "m_eps = np.zeros((dim_X))\n",
    "for i in range(n_draws):\n",
    "    eps = mvnorm(m_eps, np.diag(X_sd[i] ** 2), n_time)\n",
    "    X[i] += X[i] + eps\n",
    "    \n",
    "X = X.transpose((2, 0, 1))\n",
    "X_cov = np.einsum('ijkl,jmkl->imkl', np.expand_dims(X, 1), np.expand_dims(X, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# alpha = [10, 20, 30, 40, 50]\n",
    "alpha = [0.5, 1, 5, 10]\n",
    "# beta = [10, 20, 30, 40, 50]\n",
    "beta = [0.5, 1, 5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /Users/sikai/Dropbox/Research/post_sum/code/regain/regain/covariance/graphical_lasso_.py(93)dtrace_constraint()\n",
      "-> sqrt_term = np.sqrt(np.sum(pre_diag) ** 2 - 4 * (e - f + g) * -constraint)\n",
      "(Pdb) print(np.sum(pre_diag) ** 2)\n",
      "0.0003452474316207005\n",
      "(Pdb) print(4 * (e - f + g) * -constraint)\n",
      "0.000541478938765576\n",
      "(Pdb) loss\n",
      "0.01880974888248334\n",
      "(Pdb) constraint\n",
      "-0.5913567591292974\n"
     ]
    }
   ],
   "source": [
    "from regain.covariance import ConstrainedTimeGraphicalLasso\n",
    "tgl = ConstrainedTimeGraphicalLasso(max_iter=100, loss='DT', c_level=0.25, rho=5*1e1, psi=\"laplacian\")\n",
    "emp_inv_score, baseline_score, fit_score, pre = tgl.fit_cov(X_cov).eval_cov_pre()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/sikai/Dropbox/Research/post_sum/code/regain/regain/covariance/constrained_time_graphical_lasso.py\u001b[0m(82)\u001b[0;36mloss_dtrace\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     80 \u001b[0;31m        \u001b[0mloss_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtrace_constraint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     81 \u001b[0;31m        \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 82 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mroot_n\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mroot_p\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     83 \u001b[0;31m            \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     84 \u001b[0;31m        \u001b[0;31m# dt1.append(trace_squared_term)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> root_n\n",
      "array([1.30160646, 1.01150467, 1.05058952, 2.99586376, 3.8153693 ,\n",
      "       4.04896579, 5.08888365, 2.64631859, 4.06279915, 4.32146775,\n",
      "       4.7549685 , 3.50401953, 5.70696221, 6.17332203, 3.14721179,\n",
      "       3.38145471, 5.45706291, 5.57429919, 5.26467177, 4.40410817])\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "fig.patch.set_facecolor('white')\n",
    "# colors = \"bgrcmykw\"\n",
    "# color_index = 0\n",
    "plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(\"color\", plt.cm.tab20.colors)\n",
    "\n",
    "ax.plot(range(n_time), emp_inv_score, label=r'Empirical Inverse')\n",
    "ax.plot(range(n_time), baseline_score, label=r'Constraint')\n",
    "ax.plot(range(n_time), fit_score, label=r'TGL')\n",
    "\n",
    "fig.legend(fontsize=15)\n",
    "ax.set_ylabel('DTrace Loss', fontsize=15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.set_xlabel('Time t', fontsize=15)\n",
    "ax.set_title(r'DTrace Loss for Empirical Inverse, Constraint, TGL', fontsize=20)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('diff_like_{}_{}.pdf'.format(dim_X, dim_fac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "fig.patch.set_facecolor('white')\n",
    "# colors = \"bgrcmykw\"\n",
    "# color_index = 0\n",
    "plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(\"color\", plt.cm.tab20.colors)\n",
    "\n",
    "ax.plot(range(n_time), emp_inv_score, label=r'Empirical Inverse')\n",
    "ax.plot(range(n_time), baseline_score, label=r'Constraint')\n",
    "ax.plot(range(n_time), fit_score, label=r'TGL')\n",
    "\n",
    "fig.legend(fontsize=15)\n",
    "ax.set_ylabel('DTrace Loss', fontsize=15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.set_xlabel('Time t', fontsize=15)\n",
    "ax.set_title(r'DTrace Loss for Empirical Inverse, Constraint, TGL', fontsize=20)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('diff_like_{}_{}.pdf'.format(dim_X, dim_fac))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "from regain.covariance import TimeGraphicalLasso\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "fig.patch.set_facecolor('white')\n",
    "# colors = \"bgrcmykw\"\n",
    "# color_index = 0\n",
    "plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(\"color\", plt.cm.tab20.colors)\n",
    "\n",
    "fit_pre = {}\n",
    "emp_pre = {}\n",
    "\n",
    "for i in alpha:\n",
    "    for j in beta:\n",
    "        tgl = TimeGraphicalLasso(alpha=i, beta=j, max_iter=5000, psi=\"laplacian\", gamma=0.9)\n",
    "        emp_diff, sam_diff, pre = tgl.fit_cov(X_cov).eval_cov_pre(X_cov)    \n",
    "        emp_pre[i, j] = tgl.emp_inv\n",
    "        fit_pre[i, j] = pre\n",
    "    #     print(emp_diff, np.mean(sam_diff))\n",
    "        std = np.std(sam_diff, 1)\n",
    "\n",
    "        ax.plot(range(n_time), emp_diff, alpha=0.5, label=r'$\\alpha, \\beta$ = {},  {}'.format(i, j))\n",
    "#         ax.plot(range(n_time), emp_diff, color=colors[color_index], alpha=0.5, label=r'$\\alpha, \\beta$ = {},  {}'.format(i, j))\n",
    "#         ax.fill_between(range(n_time), emp_diff, emp_diff - std, color=colors[color_index], alpha=0.2)\n",
    "#         ax.fill_between(range(n_time), emp_diff, emp_diff + std, color=colors[color_index], alpha=0.2)\n",
    "#         color_index += 1\n",
    "        print(\"{} {} done\".format(i, j))\n",
    "\n",
    "fig.legend(fontsize=15)\n",
    "ax.set_ylabel('Difference in Log Likelihood', fontsize=15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.set_xlabel('Time t', fontsize=15)\n",
    "ax.set_title(r'Difference in Losses across $\\alpha, \\beta$s', fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('diff_like_{}_{}.pdf'.format(dim_X, dim_fac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "fig.patch.set_facecolor('white')\n",
    "# colors = \"bgrcmykw\"\n",
    "# color_index = 0\n",
    "\n",
    "ax.plot(range(n_time), [sum(sum(abs(tgl.emp_inv[k]) > 0)) for k in range(n_time)], label=r'Empirical Inverse')\n",
    "ax.plot(range(n_time), [sum(sum(abs(pre[k]) > 0)) for k in range(n_time)], label=r'TGL')\n",
    "\n",
    "fig.legend(fontsize=15)\n",
    "ax.set_ylabel('Sparsity', fontsize=15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.set_xlabel('Time t', fontsize=15)\n",
    "ax.set_title(r'Sparsity for Empirical Inverse and TGL', fontsize=20)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('diff_supp_{}_{}.pdf'.format(dim_X, dim_fac))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "fig.patch.set_facecolor('white')\n",
    "# colors = \"bgrcmykw\"\n",
    "# color_index = 0\n",
    "plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(\"color\", plt.cm.tab20.colors)\n",
    "\n",
    "for i in alpha:\n",
    "    for j in beta:\n",
    "        ax.plot(range(n_time), [sum(sum(emp_pre[(i, j)][k] > 0)) - sum(sum(fit_pre[(i, j)][k] > 0)) for k in range(n_time)], alpha=0.5, label=r'$\\alpha, \\beta$ = {},  {}'.format(i, j))\n",
    "\n",
    "fig.legend(fontsize=15)\n",
    "ax.set_ylabel('Difference in Sparsity', fontsize=15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.set_xlabel('Time t', fontsize=15)\n",
    "ax.set_title(r'Difference in Sparsity across $\\alpha, \\beta$s', fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('diff_supp_{}_{}.pdf'.format(dim_X, dim_fac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "fig.patch.set_facecolor('white')\n",
    "# colors = \"bgrcmykw\"\n",
    "# color_index = 0\n",
    "plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(\"color\", plt.cm.tab20.colors)\n",
    "\n",
    "diff_fit = [norm(pre[k] - pre[k-1], 'fro') for k in range(1, 100)]\n",
    "diff_emp = [norm(tgl.emp_inv[k] - tgl.emp_inv[k-1], 'fro') for k in range(1, 100)]\n",
    "ax.plot(range(1, n_time), np.array(diff_fit), alpha=1, label=r'Empirical Inverse')\n",
    "ax.plot(range(1, n_time), np.array(diff_emp), alpha=1, label=r'TGL')\n",
    "\n",
    "        \n",
    "fig.legend(fontsize=15)\n",
    "ax.set_ylabel('Difference in Frobenius Norm', fontsize=15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.set_xlabel('Time t', fontsize=15)\n",
    "ax.set_title(r'Difference in Frobenius Norm for Empirical Inverse and TGL', fontsize=20)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('diff_fro_{}_{}.pdf'.format(dim_X, dim_fac))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "fig.patch.set_facecolor('white')\n",
    "# colors = \"bgrcmykw\"\n",
    "# color_index = 0\n",
    "plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(\"color\", plt.cm.tab20.colors)\n",
    "\n",
    "for i in alpha:\n",
    "    for j in beta:\n",
    "        diff_fit = [norm(fit_pre[(i, j)][k] - fit_pre[(i, j)][k-1], 'fro') for k in range(1, 100)]\n",
    "        diff_emp = [norm(emp_pre[(i, j)][k] - emp_pre[(i, j)][k-1], 'fro') for k in range(1, 100)]\n",
    "        ax.plot(range(1, n_time), np.array(diff_emp) - np.array(diff_fit), alpha=0.5, label=r'$\\alpha, \\beta$ = {},  {}'.format(i, j))\n",
    "\n",
    "fig.legend(fontsize=15)\n",
    "ax.set_ylabel('Difference in Frobenius Norm', fontsize=15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.set_xlabel('Time t', fontsize=15)\n",
    "ax.set_title(r'Difference in Frobenius Norm across $\\alpha, \\beta$s', fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('diff_fro_{}_{}.pdf'.format(dim_X, dim_fac))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
